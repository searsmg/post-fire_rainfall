---
title: "mrms vs TB"
author: "Megan Sears"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = F,
  message = F, 
  warning  = F)

# load packages
library(here)
library(tidyverse)
library(lubridate)
library(zoo)
library(terra)
library(parallel)
library(doParallel)
library(data.table)
library(dataRetrieval)
library(plotly)
library(raster)
library(mapview)
library(ggExtra)

# load the functions to process TB & mrms events
load('./R/rain_metrics.Rdata')
source('./R/mrms_metrics.R')

```

# Read in TB points 

```{r}

# bring in all TBs
tb_loc <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y) 

tb_spat <- vect(tb_loc, geom = c("x", "y"), crs = "EPSG:4326")
tb <- as(tb_spat, 'Spatial')

mapview(tb)

```

# Extract the TB pixels

```{r}

# Output dir
output_dir <- "./data/mrms_data/tb_pixels_2023/"

# raster dir
base_dir <- "./data/mrms_data/2min_2023"

# List raster filenames
filenames <- list.files("./data/mrms_data/2min_2023", pattern = ".tif", full.names = FALSE)

# Parallel processing
cl <- makeCluster(4)
registerDoParallel(cl)

# Loop for parallel processing
foreach(fileName = filenames, .packages = c("terra", "lubridate", "dplyr", 'sf', 'tidyverse')) %dopar% {
  
  # Construct full file path
  full_file_path <- file.path(base_dir, fileName)

  tb_all <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y)
  tb_locations <- vect(tb_all, geom = c("x", "y"), crs = "EPSG:4326")
  
  # tb_locations <- lar_tb_spat %>%
  #   #terra::project(., 'EPSG:26913')
  #   terra::project(., '+proj=longlat +datum=WGS84 +no_defs')

  # Pull in raster
  r <- terra::rast(full_file_path)

  names(r) <- "p_mmhr"

  # Extract using terra- zonal stats, weighted mean
  extract <- terra::extract(r, tb_locations)

  extract$site <- tb_locations$site

  timestamp <- substr(fileName, 12, 26)

  # get out of UST to MST
  extract <- extract %>%
    mutate(datetime = ymd_hms(timestamp)) %>%
    mutate(datetime = datetime - (7 * 60 * 60)) %>%
    mutate(doy = yday(datetime),
           hour = hour(datetime),
           min = minute(datetime))

  # Create output filename
  output_filename <- paste0(output_dir, "extract_", extract$doy[1], "_", extract$hour[1], "_", extract$min[1], ".csv")

  write.csv(extract, file = output_filename)

  # Return a message indicating completion
  cat("Data extraction completed for:", fileName, "\n")
}

# Stop parallel processing
stopCluster(cl)

```

## Combine csvs into 1

```{r}

# Location of individual CSVs
csv_directory <- output_dir

# List them
csv_files <- list.files(csv_directory, pattern = "\\.csv$", full.names = TRUE)

# Set cores for parallel processing
cl <- makeCluster(8)
registerDoParallel(cl)

# Function to read CSV files using data.table
read_csv_file <- function(file) {
  dt <- data.table::fread(file, na.strings = c("NA", "NaN", "N/A"))

  # Check if the filename ends with "0_0.csv" and the "datetime" column contains only dates
  if (grepl("0_0.csv$", file) && "datetime" %in% colnames(dt) &&
      all(is.na(as.POSIXct(dt$datetime, format = "%Y-%m-%d %H:%M:%S")))) {
    dt$datetime <- paste0(dt$datetime, " 00:00:00")  # Append "00:00:00" to the datetime
  }

  # Convert the "datetime" column to POSIXct format (consistent date-time format)
  dt$datetime <- as.POSIXct(dt$datetime, format = "%m/%d/%y %H:%M:%S")

  dt
}

# Use foreach to read all CSV files in parallel
result <- foreach(file = csv_files, .packages = "data.table") %dopar% {
  read_csv_file(file)
}

# Stop
stopCluster(cl)

# Combine the list of data.tables into a single data.table
final_data <- rbindlist(result)

# Check the dimensions of the final_data
print(dim(final_data))

final_data <- final_data %>%
  arrange(datetime) %>%
  mutate(p_mmhr = if_else(p_mmhr < 0, 0, p_mmhr),
         p_mm = p_mmhr*(1/30)) %>%
  dplyr::select(-c(V1, doy, hour, min)) %>%
  rename(MI2_mmhr = p_mmhr)

# Write the combined data to csv
write.csv(final_data, './data/mrms_data/tb_pixels_2023/tb_pixels23.csv')

```

Ran the above for all the groups (2021, 2022, 2022, 2023)

# RQI

Get RQI for TB pixels

```{r}

# Output dir
output_dir <- "./data/mrms_data/RQI/tb_pixel23/"

# raster dir
base_dir <- "./data/mrms_data/RQI/2023/RQI_crop_bbox2fires"

# List raster filenames
filenames <- list.files(base_dir, pattern = ".tif", full.names = FALSE)

# Parallel processing
cl <- makeCluster(4)
registerDoParallel(cl)

# Loop for parallel processing
foreach(fileName = filenames, .packages = c("terra", "lubridate", "dplyr", 'sf', 'tidyverse')) %dopar% {
  
  # Construct full file path
  full_file_path <- file.path(base_dir, fileName)

  tb_all <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y)
  tb_locations <- vect(tb_all, geom = c("x", "y"), crs = "EPSG:4326")
  
  # Pull in raster
  r <- terra::rast(full_file_path)

  names(r) <- "RQI"

  # Extract using terra- zonal stats, weighted mean
  extract <- terra::extract(r, tb_locations)

  extract$site <- tb_locations$site

  timestamp <- substr(fileName, 25, 39)

  # get out of UST to MST
  extract <- extract %>%
    mutate(datetime = ymd_hms(timestamp)) %>%
    mutate(datetime = datetime - (7 * 60 * 60)) %>%
    mutate(doy = yday(datetime),
           hour = hour(datetime),
           min = minute(datetime))

  # Create output filename
  output_filename <- paste0(output_dir, "extract_", extract$doy[1], "_", extract$hour[1], "_", extract$min[1], ".csv")

  write.csv(extract, file = output_filename)

  # Return a message indicating completion
  cat("Data extraction completed for:", fileName, "\n")
}

# Stop parallel processing
stopCluster(cl)

```

## Combine csvs into 1

```{r}

# Location of individual CSVs
csv_directory <- output_dir

# List them
csv_files <- list.files(csv_directory, pattern = "\\.csv$", full.names = TRUE)

# Set cores for parallel processing
cl <- makeCluster(8)
registerDoParallel(cl)

# Function to read CSV files using data.table
read_csv_file <- function(file) {
  dt <- data.table::fread(file, na.strings = c("NA", "NaN", "N/A"))

  # Check if the filename ends with "0_0.csv" and the "datetime" column contains only dates
  if (grepl("0_0.csv$", file) && "datetime" %in% colnames(dt) &&
      all(is.na(as.POSIXct(dt$datetime, format = "%Y-%m-%d %H:%M:%S")))) {
    dt$datetime <- paste0(dt$datetime, " 00:00:00")  # Append "00:00:00" to the datetime
  }

  # Convert the "datetime" column to POSIXct format (consistent date-time format)
  dt$datetime <- as.POSIXct(dt$datetime, format = "%m/%d/%y %H:%M:%S")

  dt
}

# Use foreach to read all CSV files in parallel
result <- foreach(file = csv_files, .packages = "data.table") %dopar% {
  read_csv_file(file)
}

# Stop
stopCluster(cl)

# Combine the list of data.tables into a single data.table
final_data <- rbindlist(result)

# Check the dimensions of the final_data
print(dim(final_data))

final_data <- final_data %>%
  arrange(datetime) %>%
  dplyr::select(-c(V1, doy, hour, min))

# Write the combined data to csv
write.csv(final_data, './data/mrms_data/RQI/tb_pixels23.csv')

```

# Load pixel TB precip and RQI

The next steps:
- Load in and prep the pixel TB mrms data 
- Load in and prep RQI data to be joined with pixel TB data
- Get events & intensities for each pixel (need to add code where it's averaging RQI over the event)
- For TB data, pull time windows that align with mrms, then get the events & intens for that

```{r}

# load in pixel data
pixel21 <- read_csv('./data/mrms_data/tb_pixels_2021/tb_pixels21.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T) 
# stupidly had repeats in the tb pixel lat long file for the pixel extract
# so have to remove the repeats

pixel22 <- read_csv('./data/mrms_data/tb_pixels_2022/tb_pixels22.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

# get rid of lpm and drowsy bc they aren't covered here
pixel23 <- read_csv('./data/mrms_data/tb_pixels_2023/tb_pixels23.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

# bind together all - now I think we want to find the events & intens
pixel <- bind_rows(pixel21, pixel22, pixel23) %>%
  mutate(year = year(datetime))
    
rqi23 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels23.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi22 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels22.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi21 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels21.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi <- bind_rows(rqi23, rqi22, rqi21) %>%
  dplyr::select(-month)

both <- left_join(pixel, rqi, by = c('site','datetime'))

```

# Pixel events
Don't need to run anymore

```{r}

# right now getting it into 10 min timesteps since the smallest MI we do is 10
pixel10 <- both %>%
  mutate(timestamps_10min = ceiling_date(datetime, "10 mins")) %>%
  mutate(RQI = if_else(RQI < 0, 0, RQI),
         p_mm = if_else(p_mm < 0.1, 0, p_mm)) %>%
  group_by(site, timestamps_10min) %>%
  summarize(rain_mm = sum(p_mm), 
            rqi = mean(RQI, na.rm=T)) %>%
  rename(datetime = timestamps_10min)


get_rqi_events <- function(ID_name) {
  rqi_events <- pixel10 %>%
  filter(site == ID_name,
         rain_mm >= 0.1) %>%
  get_mrms_events(., datetime)
  
  return(rqi_events)
}

# list out sites
sites <- unique(pixel10$site)

# get events for all sites
rqi_events <- map(sites, ~ get_rqi_events(.)) %>%
  bind_rows()

# join this back later by site and event
rqi_mean <- rqi_events %>%
  group_by(site, event) %>%
  summarize(mean_rqi = mean(rqi, na.rm = T))

# list out sites
sites <- unique(pixel10$site)

# get events for all sites
pixel_events <- map(sites, ~ get_mrms_all_events(pixel10, .)) %>%
  bind_rows()

# get intens for all sites
pixel_intens <- map(sites, ~ get_mrms_intensities(pixel_events, .)) %>%
  bind_rows(.)

# pixel_intens <- pixel_intens %>%
#   group_by(site) %>%
#   arrange(event) %>%
#   mutate(event = 1:n()) %>%
#   mutate(year = year(start_time)) #%>%
  # mutate(site = case_when(
  #   site == 'HUm2' ~ 'hum2',
  #   site == 'LPm' ~ 'lpm',
  #   site == 'MUb' ~ 'mub',
  #   site == 'm_e' ~ 'me',
  #   site == 'm_m' ~ 'mm',
  #   site == 'm_w' ~ 'mw',
  #   site == 'u_e' ~ 'ue',
  #   site == 'u_m' ~ 'um',
  #   site == 'u_w' ~ 'uw',
  #   TRUE ~ site))

ggplot(pixel_intens, aes(y=MI60_mmhr, x=site)) + geom_boxplot()
ggplot(pixel_intens, aes(y=event_sum_mm, x=site)) + geom_boxplot()

#write_csv(pixel_intens, './data/final/mrms/pixel_compare/pixel10_events_ours2.csv')
# write_csv(rqi_mean, './data/final/mrms/pixel_compare/rqi_events_mean.csv')

pixel_intens <- read_csv('./data/final/mrms/pixel_compare/pixel_events/pixel10_events_ours2.csv') %>%
  force_tz(datetime, tzone = 'MST')

```

# Read in TB data

```{r}
# read in tb data
cpf_tb <- read_csv('./data/TB_raw/cpf_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

etf_tb <- read_csv('./data/TB_raw/et_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

ben_tb <- read_csv('./data/TB_raw/bennett_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

```

# Read in USGS TB data

```{r}

willow_upper <- readNWISuv(siteNumber = 401642106051601, 
                           parameterCd = "00045") %>% 
  dplyr::select(datetime = 3, P_in = 4) %>% # tz is in UTC
  mutate(p_mm = P_in * 25.4,
         datetime = with_tz(datetime, tzone = 'MST'),
         site = 'willowcr_upper') %>%
  dplyr::select(-P_in)

drowsy <- readNWISuv(siteNumber = 400912106031201, 
                     parameterCd = "00045") %>%
  dplyr::select(datetime = 3, P_in = 4) %>% # tz is in UTC
  mutate(p_mm = P_in * 25.4,
         datetime = with_tz(datetime, tzone = 'MST'),
         site = 'drowsy') %>%
  dplyr::select(-P_in)

usgs <- bind_rows(willow_upper, drowsy)

# now bind all together - select only June - Sept
tb <- bind_rows(cpf_tb, etf_tb, ben_tb, usgs) %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9))

```

# Process TB events -- ONLY NEEDED FOR TESTING WINDOWS

```{r}

load('./R/rain_metrics.RData')

dadd_tb <- read_csv('./data/cpf_TB_rain.csv') %>%
  filter(site == 'dadd') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  arrange(datetime) %>%
  mutate(P_mm = 0.254)

dadd_tb <- get_setup(dadd_tb, dadd_tb$datetime)

dadd_events <- get_events(dadd_tb, dadd_tb$P_mm, dadd_tb$datenumeric,
                          dadd_tb$end, dadd_tb$rain_start)

dadd_events <- get_intensities(dadd_events, dadd_events$event, dadd_tb)

#me 
# me_rain <- get_setup(me_rain, me_rain$datetime)
# me_events <- get_events(me_rain, me_rain$P_mm, me_rain$datenumeric,
#                         me_rain$end, me$rain_start)
# me_events <- get_intensities(me_events, me_events$event, me_rain)

dadd_events <- dadd_events %>%
  mutate(starttime = as.character(starttime),
         endtime = as.character(endtime))

write_csv(dadd_events, './data/final/mrms/pixel_compare/dadd_obs_events.csv')

```

# Filter TB data based on pixel event windows

```{r}

pixel10_intens <- read_csv('./data/final/mrms/pixel_compare/pixel_events/pixel10_events_ours2.csv') %>%
  mutate(start_time = with_tz(start_time, 'MST'),
         end_time = with_tz(end_time, 'MST')) %>%
  mutate(site = case_when(
    site == 'HUm2' ~ 'hum2',
    site == 'LPm' ~ 'lpm',
    site == 'MUb' ~ 'mub',
    site == 'm_e' ~ 'me',
    site == 'm_m' ~ 'mm',
    site == 'm_w' ~ 'mw',
    site == 'u_e' ~ 'ue',
    site == 'u_m' ~ 'um',
    site == 'u_w' ~ 'uw',
    TRUE ~ site))
         
site_name <- unique(pixel10_intens$site)

tb_filter <- map_df(site_name, filter_tb) %>% 
  arrange(datetime) 

# filter some things to just see mont to make sure above code is good - ONLY FOR TESTING
# mont_tb <- tb %>%
#   filter(site == 'montgomery')
# 
# mont_pixel <- pixel10_intens %>%
#   filter(site == 'montgomery')

```

# TB filtered (based on pixel events) events

```{r}

# get events for tb_filter
tb_fil10 <- tb_filter %>%
  mutate(timestamps_10min = ceiling_date(datetime, "10 mins")) %>%
  group_by(site, timestamps_10min) %>%
  summarize(rain_mm = sum(p_mm),
            event_mrms = mean(event_mrms)) %>%
  rename(datetime = timestamps_10min) 


sites <- unique(tb_fil10$site)

# get events for all sites
tbfil_events <- map(sites, ~ get_mrms_all_events(tb_fil10, .)) %>%
  bind_rows()

tbfil_intens <- map(sites, ~ get_mrms_intensities(tbfil_events, .)) %>%
  bind_rows()

pixel_intens <- pixel10_intens %>%
  #filter(site == site_name) %>% # update later
  rename(event_mrms = event)

comp_intens <- left_join(pixel_intens, tbfil_intens, by = c('site', 'event_mrms'))

```

# Filter for when no TB data
## ETF

Do ETF first -
Some quick filters:
-ET TBs did not run before 6/20/22 (p1, mub, hum2, lpm)

```{r}

comp_etf <- comp_intens %>%
  filter(site %in% c("p1", "mub", "lpm", "hum2")) %>%
  filter(start_time.x > ymd_hms('2022-06-20 11:00:00', tz = 'MST')) %>%
  mutate(
    condition = case_when(
      site == 'hum2' &
        start_time.x > ymd_hms('2022-08-04 11:16:00', tz = 'MST') ~ 'remove',
      site == 'p1' &
        start_time.x > ymd_hms('2022-07-12 08:36:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-07-21 16:00:00', tz = 'MST') ~ 'remove',
      site == 'p1' &
        start_time.x > ymd_hms('2023-07-21 23:57:00', tz = 'MST') ~ 'remove',
      site == 'lpm' &
        start_time.x > ymd_hms('2022-10-18 10:23:00', tz = 'MST') &
        start_time.x < ymd_hms('2023-05-24 13:20:00', tz = 'MST') ~ 'remove',
      site == 'lpm' &
        start_time.x > ymd_hms('2023-06-11 16:55:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
    )
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

# write this to csv so it doesnt have to be run anymore
# add etf so i can combine it to cpf later
comp_etf <- comp_etf %>%
  mutate(fire = 'ETF')

write.csv(comp_etf, './data/final/mrms/pixel_compare/etf_pixel_compare2.csv')

# did those for mi60 and mi30
# none of the 3 (mi60, mi30, and event sum were normally distr.)
# recorded the corrs at link below:
# ./data/final/mrms/pixel_compare/compare/pixel_tb_corrs.csv
cor_coeff <- cor(comp_etf$event_sum_mm.y, 
                 comp_etf$event_sum_mm.x,
                 method = 'spearman')

cor_coeff

ggplot(data = comp_etf, aes(sample = event_sum_mm.x)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  ggtitle("Q-Q Plot for MI60_mmhr.y") +
  theme_minimal()

library(viridis)

comp_etf <- comp_etf %>%
  mutate(rqi_bucket = cut(rqi, 
                          breaks = c(0, .20, .40, .60, .80, .100),  # Define bucket boundaries
                          labels = c("0-0.2", "0.2-0.4", "0.4-0.6", "0.6-0.8", "0.8-1.0"),  # Labels
                          include.lowest = TRUE))  # Include the lowest boundary

color_palette <- brewer.pal(n = 8, name = "Dark2")[1:5]

# Plot using rqi_bucket
ggplot(comp_etf %>% arrange(desc(rqi)),  # Ensure higher rqi values are plotted first
       aes(y = MI60_mmhr.y, 
           x = MI60_mmhr.x, 
           color = rqi_bucket)) +  # Use the categorical variable
  geom_point(alpha = 0.9, 
             size = 3,
             stroke=1) +
scale_color_brewer(palette='Dark2') +
  geom_abline(intercept = 0, 
              slope = 1, 
              linetype = "dashed", 
              color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB') +
    theme_bw(base_size = 20) +
    theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black")) 


ggplot(comp_etf %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
       aes(y = MI60_mmhr.y, 
           x = MI60_mmhr.x, 
           color = rqi)) + 
  geom_point(alpha = 0.9, 
             size = 3) +
  scale_color_viridis(option = "magma") + 
  geom_abline(intercept = 0, 
              slope = 1, 
              linetype = "dashed", 
              color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_etf, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point(aes(#color = rqi > 0.4,
                 alpha=1)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$MI10_mmhr.y, comp_etf$MI10_mmhr.x)

ggplot(comp_etf, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$event_sum_mm.y, comp_etf$event_sum_mm.x)

ggplot(comp_etf, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$MI30_mmhr.y, comp_etf$MI30_mmhr.x)

ggplot(comp_etf, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

```

## Bennett

```{r}

comp_benn <- comp_intens %>%
  filter(site %in% c("mm", "me", "mw", "ue", "um", "uw")) %>%
  mutate(
    condition = case_when(
      site == 'me' &
        start_time.x < ymd_hms('2021-07-19 15:45:00', tz = 'MST') ~ 'remove',
      site == 'me' &
        start_time.x > ymd_hms('2021-10-21 14:00:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-06-16 11:00:00', tz = 'MST') ~ 'remove',
      site == 'me' & 
        start_time.x > ymd_hms('2023-09-07 15:45:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x < ymd_hms('2021-09-06 13:30:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2021-10-12 15:35:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-22 10:00:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2022-06-07 01:25:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-08-10 10:00:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2022-12-15 19:55:00', tz = 'MST') &
        start_time.x < ymd_hms('2023-06-09 09:15:00', tz = 'MST') ~ 'remove',
      site == 'mm' & 
        start_time.x > ymd_hms('2023-09-28 13:10:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x < ymd_hms('2021-08-20 10:50:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x > ymd_hms('2021-10-14 12:42:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-06 12:00:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x > ymd_hms('2022-07-06 12:10:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-08-03 10:15:00', tz = 'MST') ~ 'remove',
      site == 'mw' & 
        start_time.x > ymd_hms('2023-09-19 15:05:00', tz = 'MST') ~ 'remove',
      site == 'ue' &
        start_time.x < ymd_hms('2021-09-06 13:00:00', tz = 'MST') ~ 'remove',
      site == 'ue' &
        start_time.x > ymd_hms('2021-10-12 13:17:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-07 12:00:00', tz = 'MST') ~ 'remove',
      site == 'mw' & 
        start_time.x > ymd_hms('2023-05-22 11:33:00', tz = 'MST') ~ 'remove',
      site == 'um' & 
        start_time.x < ymd_hms('2021-07-26 13:30:00', tz = 'MST') ~ 'remove',
      site == 'um' & 
        start_time.x > ymd_hms('2021-07-31 13:32:00', tz = 'MST') ~ 'remove',
      site == 'uw' & 
        start_time.x < ymd_hms('2021-07-19 14:00:00', tz = 'MST') ~ 'remove',
      site == 'uw' & 
        start_time.x > ymd_hms('2023-09-07 14:05:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep')) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)
  ) %>%
    filter(!site %in% c('um'))

comp_benn <- comp_benn %>%
  mutate(fire = 'CPF')

# filter <- comp_benn
# 
# cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)
# 
# ggplot(filter %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
#        aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
#   geom_point(alpha = 0.7, size = 3) +
#   scale_color_distiller(palette = "Spectral") +  # Use a continuous ColorBrewer palette
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('benn MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('benn MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)
# 
# ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('benn MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)
# 
# ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('benn event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)
# 
# ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('benn MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')

```

Montgomery test

```{r}

comp_mont <- comp_intens %>%
  mutate(condition = case_when(
          site == 'montgomery' &
        start_time.x < ymd_hms('2021-06-11 10:00:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x > ymd_hms('2023-09-19 19:00:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
  ))


ggplot(comp_mont, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('MI60:', paste("R2 =", round(summary(lm(comp_mont$MI60_mmhr.y ~ comp_mont$MI60_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')


ggplot(comp_mont, aes(y = MI10_mmhr.y, x = MI10_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$MI10_mmhr.y ~ comp_mont$MI10_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_mont, aes(y = event_sum_mm.y, x = event_sum_mm.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$event_sum_mm.y ~ comp_mont$event_sum_mm.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_mont, aes(y = MI30_mmhr.y, x = MI30_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$MI30_mmhr.y ~ comp_mont$MI30_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')


```

## CPF sites

```{r}

comp_cpf <- comp_intens %>%
  filter(site %in% c('aspen', 'bighorn', 'bl4', 'dadd', 'dry', 'michigan', 'montgomery', 'mtcampus')) %>%
  mutate(
    condition = case_when(
      site == 'aspen' &
        start_time.x < ymd_hms('2021-05-18 14:30:00', tz = 'MST') ~ 'remove',
      site == 'aspen' &
        start_time.x > ymd_hms('2021-06-28 11:56:00', tz = 'MST') &
        start_time.x < ymd_hms('2021-10-7 15:00:00', tz = 'MST') ~ 'remove',
      site == 'aspen' &
        start_time.x > ymd_hms('2023-09-21 12:45:00', tz = 'MST') ~ 'remove',
      site == 'bighorn' &
        start_time.x < ymd_hms('2021-05-07 11:20:00', tz = 'MST') ~ 'remove',
      site == 'bl4' &
        start_time.x < ymd_hms('2021-06-11 13:00:00', tz = 'MST') ~ 'remove',
      site == 'bl4' &
        start_time.x > ymd_hms('2023-09-04 14:15:00', tz = 'MST') ~ 'remove',
      site == 'dadd' &
        start_time.x > ymd_hms('2022-05-12 15:00:00', tz = 'MST') ~ 'remove',
      site == 'dry' &
        start_time.x < ymd_hms('2021-05-18 11:15:00', tz = 'MST') ~ 'remove',
      site == 'michigan' &
        start_time.x > ymd_hms('2021-10-24 11:15:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x < ymd_hms('2021-06-11 10:00:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x > ymd_hms('2023-09-19 19:00:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
    )
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

comp_cpf <- comp_cpf %>%
  mutate(fire = 'CPF')

comp_cpf_all <- bind_rows(comp_cpf, comp_benn)

write.csv(comp_cpf_all, './data/final/mrms/pixel_compare/compare/cpf_pixel_compare2.csv')

# now check correlations - rerunf or all 3 metrics (and for both x and y)
ggplot(data = comp_cpf_all, aes(sample = event_sum_mm.y)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  ggtitle("Q-Q Plot for MI60_mmhr.y") +
  theme_minimal()

# none were normally distrb. so using spearman
cor_coeff <- cor(comp_cpf_all$event_sum_mm.y, 
                 comp_cpf_all$event_sum_mm.x,
                 method = 'spearman')

cor_coeff


# cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)
# 
# ggplot(filter %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
#        aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
#   geom_point(alpha = 0.7, size = 3) +
#   scale_color_distiller(palette = "Spectral") +  # Use a continuous ColorBrewer palette
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('cpf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
#   #geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('cpf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)
# 
# ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('cpf MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)
# 
# ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('cpf event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')
# 
# cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)
# 
# ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
#   geom_point(aes(color = rqi > 0.4)) +
#   scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('cpf MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')

```

## Combine ETF and CPF

### Correlation by site

```{r}
# the csvs for this is located here: 
# ./data/final/mrms/pixel_compare/compare
# so dont run above

comp_all <- bind_rows(comp_cpf_all, comp_etf)

write_csv(comp_all, './data/final/mrms/pixel_compare/compare/comp_cpf_etf2.csv')

ggplot(data = comp_etf, aes(sample = event_sum_mm.y)) +
  stat_qq() +
  stat_qq_line(color = "red")

# cpf
# mi60 x = not normal, mi60 y = not normal
# mi30 x = not normal, mi30 y = not normal
# event sum x = not normal, event sum y = not normal

# etf 
# mi60 x = not normal, mi60 y = not normal
# mi30 x = not normal, mi30 y = not normal
# event sum x = not normal, event sum y = not normal


corrs_all <- comp_all %>%
  group_by(site) %>%
  summarize(corr_coeff_sum = cor(event_sum_mm.y, 
                              event_sum_mm.x,
                              method = 'spearman'),
    corr_coeff_mi60 = cor(MI60_mmhr.y, 
                              MI60_mmhr.x,
                              method = 'spearman'),
    corr_coeff_mi30 = cor(MI30_mmhr.y, 
                              MI30_mmhr.x,
                              method = 'spearman'))
    
write_csv(corrs_all, './data/final/mrms/pixel_compare/compare/corr_bysite2.csv')

```

### Figures

```{r}

comp_all <- read_csv('./data/final/mrms/pixel_compare/compare/comp_cpf_etf2.csv')


library(viridis)
library(RColorBrewer)

comp_all <- comp_all %>%
  mutate(rqi_bucket = cut(rqi, 
                          breaks = c(0, .20, .40, .60, .80, 1),
                          labels = c("0-0.2", "0.2-0.4", "0.4-0.6", "0.6-0.8", "0.8-1.0"), 
                          include.lowest = TRUE))

color_palette <- c(
  "0-0.2" = "#66A61E",
  "0.2-0.4" = "#1B9E77",
  "0.4-0.6" = "#D95F02",
  "0.6-0.8" = "#7570B3",
  "0.8-1.0" = "#E7298A"
)

new_facet_titles <- c(
  "CPF" = "Cameron Peak",
  "ETF" = "East Troublesome"
)

spearman_corrs_mi30 <- comp_all %>%
  group_by(fire) %>%
  summarize(spearman_corr = cor(MI30_mmhr.y, MI30_mmhr.x, method = "spearman"))

spearman_corrs_mi60 <- comp_all %>%
  group_by(fire) %>%
  summarize(spearman_corr = cor(MI60_mmhr.y, MI60_mmhr.x, method = "spearman"))

spearman_corrs_eventsum <- comp_all %>%
  group_by(fire) %>%
  summarize(spearman_corr = cor(event_sum_mm.y, event_sum_mm.x, method = "spearman"))


# Cameron Peak
cp1 <- comp_all %>%
  filter(fire == 'CPF') %>% 
  arrange(desc(rqi)) %>%
  ggplot(., 
         aes(y = event_sum_mm.y, x = event_sum_mm.x, color = rqi_bucket)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",
           label.x = 48, 
           label.y = 72, 
           size = 4,
           hjust = 0.5,
           vjust = -1) +
  labs(x = 'MRMS event rainfall (mm)', y = 'TB event rainfall (mm)', color = 'RQI') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'none',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16))

cp1

cp_marg <- ggMarginal(cp1,
           groupColour = T,
           groupFill = T,
           type='density')

cp_marg

ggsave('./figures/pixel_tb_cpmarg_eventsum.png',
       plot = cp_marg,
       width = 7,
       height = 5,
       dpi=600)

# East Troublesome
et1 <- comp_all %>%
  filter(fire == 'ETF') %>% 
  arrange(desc(rqi)) %>%
  ggplot(., 
         aes(y = event_sum_mm.y, x = event_sum_mm.x, color = rqi_bucket)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",    # Set the correlation label color to black
           label.x = 20, 
           label.y = 25, 
           size = 4,            # Adjust label size
           hjust = 0.5,         # Center the label horizontally
           vjust = -1) +
  labs(x = 'MRMS event rainfall (mm)', y = 'TB event rainfall (mm)', color = 'RQI') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'none',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16)
  )

et1

et_marg <- ggMarginal(et1,
           groupColour = T,
           groupFill = T)

et_marg

ggsave('./figures/pixel_tb_ETmarg_eventsum.png',
       plot = et_marg,
       width = 7,
       height = 5,
       dpi=600)

```


## ETF USGS
DON'T USE ANYMORE SINCE USGS SITES USED FOR MRMS DATA

```{r}

comp_usgs <- comp_intens %>%
  filter(site %in% c('willowcr_upper', 'drowsy')) %>%
  mutate(condition = case_when(
      site == 'willowcr_upper' &
        start_time.x < ymd_hms('2022-05-01 05:00:00', tz = 'MST') ~ 'remove',
      site == 'drowsy' &
        start_time.x < ymd_hms('2022-05-19 21:10:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
  ) 
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

filter <- comp_usgs #%>%
  filter(site %in% c('drowsy'))

cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)

ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)

ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)

ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)

ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

```

# Larimer Co data

## Larimer TB

```{r}
# Don't need to run anymore

# lar_tb <- read_csv('./data/TB_raw/larimerco_precip.csv') %>%
#   rename(numid = site) %>%
#   mutate(datetime = with_tz(DT_mst, 'MST'))
#   
# lar_meta <- read_csv('./data/GIS/larimer_tb_meta.csv') %>%
#   dplyr::select(numid, site = name)
# 
# # make it so the larimer tb data has site name
# tb <- left_join(lar_tb, lar_meta, by = 'numid')
# 
# lar_names <- unique(lar_meta$site)
# site_name <- lar_names
#   
# pixel10_intens <- read_csv('./data/final/mrms/pixel_compare/pixel_events/pixel10_events_ours2.csv') %>%
#   mutate(start_time = with_tz(start_time, 'MST'),
#          end_time = with_tz(end_time, 'MST')) %>%
#   filter(site %in% lar_names)
# 
# tb_filter <- map_df(site_name, filter_tb) %>% 
#   arrange(datetime) # filter tb based on pixel events
# 
# ###
# # get events for tb_filter
# tb_fil10 <- tb_filter %>%
#   mutate(timestamps_10min = ceiling_date(datetime, "10 mins"),
#          p_mm = p_in*25.4) %>%
#   group_by(site, timestamps_10min) %>%
#   summarize(rain_mm = sum(p_mm),
#             event_mrms = mean(event_mrms)) %>%
#   rename(datetime = timestamps_10min) 
# 
# sites <- unique(tb_fil10$site)
# 
# # get events for all sites
# tbfil_events <- map(sites, ~ get_mrms_all_events(tb_fil10, .)) %>%
#   bind_rows()
# 
# tbfil_intens <- map(sites, ~ get_mrms_intensities(tbfil_events, .)) %>%
#   bind_rows()
# 
# pixel_intens <- pixel10_intens %>%
#   #filter(site == site_name) %>% # update later
#   rename(event_mrms = event)
# 
# comp_intens <- left_join(pixel_intens, tbfil_intens, by = c('site', 'event_mrms'))
# 
# ##########
# 
# filter <- comp_intens %>%
#   mutate(condition = case_when(
#       site == 'Fort Collins - Gateway Park' &
#         start_time.x > ymd_hms('2021-10-01 01:00:00', tz = 'MST') ~ 'remove',
#       site == 'Fort Collins - Rustic' &
#         start_time.x > ymd_hms('2023-09-13 13:38:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Crown Gulch Headwaters' &
#         start_time.x < ymd_hms('2023-06-27 08:59:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Turner Hill Weather' &
#         start_time.x < ymd_hms('2023-06-27 16:59:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Tunnel Creek at Hwy 14' &
#         start_time.x < ymd_hms('2022-05-31 23:59:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Chambers Resevoir' &
#         start_time.x < ymd_hms('2022-06-27 10:42:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Joe Wright Resevoir' &
#         start_time.x < ymd_hms('2022-06-14 12:59:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Roaring Creek at Hwy 14' &
#         start_time.x < ymd_hms('2021-08-11 10:59:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Long Draw Resevoir' &
#         start_time.x < ymd_hms('2022-06-24 09:13:00', tz = 'MST') ~ 'remove',
#       site == 'Larimer - Long Draw Resevoir' &
#         start_time.x > ymd_hms('2023-06-01 00:00:00', tz = 'MST') &
#         start_time.x < ymd_hms('2023-07-10 22:59:00', tz = 'MST') ~ 'remove',
#       TRUE ~ 'keep'
#   ) 
#   ) %>%
#   filter(condition == 'keep') %>%
#   filter(!site == 'Larimer - North Fork Big Thompson at Storm Mountain Road') %>% 
#   mutate(duration_hr.x = as.numeric(duration_hr.x),
#          duration_hr.y = as.numeric(duration_hr.y)) %>%
#   mutate_at(
#     c(
#       'MI60_mmhr.y',
#       'MI30_mmhr.y',
#       'MI20_mmhr.y',
#       'MI10_mmhr.y',
#       'event_sum_mm.y',
#       'duration_hr.y'),
#     ~ replace_na(., 0)) %>%
#   arrange(start_time.x)
# 
# write_csv(filter, './data/final/mrms/pixel_compare/compare/larimer_tbpixel_compare2.csv')

##############################################################################

filter <- read_csv('./data/final/mrms/pixel_compare/compare/larimer_tbpixel_compare2.csv')

spearman_corrs_mi30 <- filter %>%
  summarize(spearman_corr = cor(MI30_mmhr.y, MI30_mmhr.x, method = "spearman"))

spearman_corrs_mi60 <- filter %>%
  summarize(spearman_corr = cor(MI60_mmhr.y, MI60_mmhr.x, method = "spearman"))

spearman_corrs_eventsum <- filter %>%
  summarize(spearman_corr = cor(event_sum_mm.y, event_sum_mm.x, method = "spearman"))

filter <- filter %>%
  mutate(rqi_bucket = cut(rqi, 
                          breaks = c(0, .20, .40, .60, .80, 1),
                          labels = c("0-0.2", "0.2-0.4", "0.4-0.6", "0.6-0.8", "0.8-1.0"), 
                          include.lowest = TRUE))

plot_lar <- ggplot(filter %>% arrange(desc(rqi)), 
                aes(y = MI30_mmhr.y, x = MI30_mmhr.x, color = rqi_bucket)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",    # Set the correlation label color to black
           label.x = 75, 
           label.y = 92, 
           size = 4,            # Adjust label size
           hjust = 0.5,         # Center the label horizontally
           vjust = -1) +
  labs(x = 'MRMS MI30 (mm/hr)', y = 'TB MI30 (mm/hr)', color = 'RQI') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'none',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16)
  )

plot_lar

lar_marg <- ggMarginal(plot_lar,
           groupColour = T,
           groupFill = T)

lar_marg

ggsave('./figures/pixel_tb_LARmarg_MI30.png',
       plot = lar_marg,
       width = 7,
       height = 5,
       dpi=600)

# Corr by site
comp_r2 <- filter %>%
  group_by(site) %>%
  summarize(mi60_cor = cor(MI60_mmhr.y, MI60_mmhr.x,
                           method = 'spearman'),
         mi30_cor = cor(MI30_mmhr.y, MI30_mmhr.x,
                         method = 'spearman'),
         mi10_cor = cor(MI10_mmhr.y, MI10_mmhr.x,
                         method = 'spearman'),
         eventsum_cor = cor(event_sum_mm.y, event_sum_mm.x,
                             method = 'spearman'))


# export larimer tb.pixel event data
write_csv(comp_r2, './data/final/mrms/pixel_compare/compare/larimer_tbpixel_cor2.csv')

```

## Check Larimer TB record

Make this ggplot so I can check dates.

I added these filtered dates above

```{r}

#function to plot all params
plot_params <- function(site_name) {
  {tb %>%
      filter(site == site_name) %>%
      ggplot(aes(x = datetime, y = p_in)) +
      geom_line() + 
      ggtitle(site_name) +
      theme_bw()} %>%
      ggplotly()
}

name <- unique(tb$site)

plots <- lapply(name, plot_params)
plots

```

## Figs by elev

```{r}

# join together the larimer and cpf/etf datasets
larimer <- filter %>%
  mutate(fire = 'larimer')

tbPixAll <- bind_rows(comp_all, larimer)

dem <- rast('./data/GIS/dem_10m.tif')

tb_loc <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site2, x, y) 

tb_spat <- vect(tb_loc, geom = c("x", "y"), crs = "EPSG:4326")

tb_xy <- dem %>%
  terra::extract(tb_spat, 
                 fun = mean, 
                 ID = T) %>%
  mutate(site = tb_spat$site2)
  
comp_elev <- left_join(tbPixAll, tb_xy, by = 'site') %>%
  rename(elev_m = USGS_13_n41w106_20230314)

# create elevation bins
comp_elev <- comp_elev %>%
  mutate(
    elevation_bin = cut(
      elev_m,
      breaks = seq(1550, 3600, by = 250),
      include.lowest = TRUE)) %>%
  separate(elevation_bin, 
           into = c("bin_start", "bin_end"), 
           sep = ",", 
           convert = TRUE) %>%
   mutate(bin_start = as.numeric(str_remove_all(bin_start, "[\\[\\]()]")),
    bin_end = as.numeric(str_remove_all(bin_end, "[\\[\\]()]"))) %>% 
  mutate(median_elev = as.character((bin_start + bin_end) / 2))

color_palette <- c(
  "1675" = "#66A61E",
  "1925" = "#1B9E77",
  "2175" = "#D95F02",
  "2425" = "#7570B3",
  "2675" = "#E7298A",
  "2925" = "#666666",
  "3175" = "#E6AB02",
  "3425" = "#A6761D"
)

# Cameron Peak
cp1 <- comp_elev %>%
  filter(fire == 'CPF') %>% 
  arrange(desc(median_elev)) %>%
  ggplot(., 
         aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = median_elev)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",
           label.x = 30, 
           label.y = 43, 
           size = 4,
           hjust = 0.5,
           vjust = -1) +
  labs(x = 'MRMS MI60 (mm/hr)', y = 'TB MI60 (mm/hr)', color = '') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'none',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16))

cp1

cp_marg <- ggMarginal(cp1,
           groupColour = T,
           groupFill = T,
           type='density')

cp_marg

ggsave('./figures/pixel_tb_cpElev_MI60.png',
       plot = cp_marg,
       width = 7,
       height = 5,
       dpi=600)

# East Troublesome
et1 <- comp_elev %>%
  filter(fire == 'ETF') %>% 
  arrange(desc(median_elev)) %>%
  ggplot(., 
         aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = median_elev)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",    # Set the correlation label color to black
           label.x = 11, 
           label.y = 16, 
           size = 4,            # Adjust label size
           hjust = 0.5,         # Center the label horizontally
           vjust = -1) +
  labs(x = 'MRMS MI60 (mm)', y = 'TB MI60 (mm)', color = 'RQI') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'none',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16)
  )

et1

et_marg <- ggMarginal(et1,
           groupColour = T,
           groupFill = T)

et_marg

ggsave('./figures/pixel_tb_ETelev_MI60.png',
       plot = et_marg,
       width = 7,
       height = 5,
       dpi=600)

# Larimer county
plot_lar <- comp_elev %>%
    filter(fire == 'larimer') %>% 
  arrange(desc(median_elev)) %>%
  ggplot(., 
         aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = median_elev)) +
  geom_point(alpha = 0.6, size = 4, stroke = 1) +
  scale_color_manual(values = color_palette) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
   stat_cor(method = "spearman", 
           color = "black",    # Set the correlation label color to black
           label.x = 45, 
           label.y = 62, 
           size = 4,            # Adjust label size
           hjust = 0.5,         # Center the label horizontally
           vjust = -1) +
  labs(x = 'MRMS MI60 (mm/hr)', y = 'TB MI60 (mm/hr)', color = 'Elevation (m)') +
  theme_bw(base_size = 18) +
  theme(
    panel.grid = element_blank(),
    panel.background = element_rect(fill = "white"),
    strip.background = element_blank(),
    text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    axis.text = element_text(color = "black"),
    legend.position = 'bottom',
    legend.justification = c(0, 1.1), 
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 16)
  )

plot_lar

ggplotly(plot_lar)

ggsave('./figures/pixel_tb_elev_legend.png',
       plot = plot_lar,
       width = 7,
       height = 5,
       dpi=600)

lar_marg <- ggMarginal(plot_lar,
           groupColour = T,
           groupFill = T)

lar_marg

ggsave('./figures/pixel_tb_LARelev_MI60.png',
       plot = lar_marg,
       width = 7,
       height = 5,
       dpi=600)

ggplotly(p=plot_lar)

plot_ly(
  data = comp_elev,
  x = ~MI60_mmhr.x,
  y = ~MI60_mmhr.y,
  color = ~median_elev,
  type = "scatter",
  mode = "markers"
)


```

