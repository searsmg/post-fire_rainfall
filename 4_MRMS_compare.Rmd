---
title: "mrms vs TB"
author: "Megan Sears"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = F,
  message = F, 
  warning  = F)

# load packages
library(here)
library(tidyverse)
library(lubridate)
library(zoo)
library(terra)
library(parallel)
library(doParallel)
library(data.table)
library(dataRetrieval)
library(plotly)
library(raster)
library(mapview)

# load the functions to process TB & mrms events
load('./R/rain_metrics.Rdata')
source('./R/mrms_metrics.R')

```

# Read in TB points 

```{r}

# bring in all TBs
tb_loc <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y) 

tb_spat <- vect(tb_loc, geom = c("x", "y"), crs = "EPSG:4326")
tb <- as(tb_spat, 'Spatial')

mapview(tb)

```

# Extract the TB pixels

```{r}

# Output dir
output_dir <- "./data/mrms_data/tb_pixels_2023/"

# raster dir
base_dir <- "./data/mrms_data/2min_2023"

# List raster filenames
filenames <- list.files("./data/mrms_data/2min_2023", pattern = ".tif", full.names = FALSE)

# Parallel processing
cl <- makeCluster(4)
registerDoParallel(cl)

# Loop for parallel processing
foreach(fileName = filenames, .packages = c("terra", "lubridate", "dplyr", 'sf', 'tidyverse')) %dopar% {
  
  # Construct full file path
  full_file_path <- file.path(base_dir, fileName)

  tb_all <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y)
  tb_locations <- vect(tb_all, geom = c("x", "y"), crs = "EPSG:4326")
  
  # tb_locations <- lar_tb_spat %>%
  #   #terra::project(., 'EPSG:26913')
  #   terra::project(., '+proj=longlat +datum=WGS84 +no_defs')

  # Pull in raster
  r <- terra::rast(full_file_path)

  names(r) <- "p_mmhr"

  # Extract using terra- zonal stats, weighted mean
  extract <- terra::extract(r, tb_locations)

  extract$site <- tb_locations$site

  timestamp <- substr(fileName, 12, 26)

  # get out of UST to MST
  extract <- extract %>%
    mutate(datetime = ymd_hms(timestamp)) %>%
    mutate(datetime = datetime - (7 * 60 * 60)) %>%
    mutate(doy = yday(datetime),
           hour = hour(datetime),
           min = minute(datetime))

  # Create output filename
  output_filename <- paste0(output_dir, "extract_", extract$doy[1], "_", extract$hour[1], "_", extract$min[1], ".csv")

  write.csv(extract, file = output_filename)

  # Return a message indicating completion
  cat("Data extraction completed for:", fileName, "\n")
}

# Stop parallel processing
stopCluster(cl)

```

## Combine csvs into 1

```{r}

# Location of individual CSVs
csv_directory <- output_dir

# List them
csv_files <- list.files(csv_directory, pattern = "\\.csv$", full.names = TRUE)

# Set cores for parallel processing
cl <- makeCluster(8)
registerDoParallel(cl)

# Function to read CSV files using data.table
read_csv_file <- function(file) {
  dt <- data.table::fread(file, na.strings = c("NA", "NaN", "N/A"))

  # Check if the filename ends with "0_0.csv" and the "datetime" column contains only dates
  if (grepl("0_0.csv$", file) && "datetime" %in% colnames(dt) &&
      all(is.na(as.POSIXct(dt$datetime, format = "%Y-%m-%d %H:%M:%S")))) {
    dt$datetime <- paste0(dt$datetime, " 00:00:00")  # Append "00:00:00" to the datetime
  }

  # Convert the "datetime" column to POSIXct format (consistent date-time format)
  dt$datetime <- as.POSIXct(dt$datetime, format = "%m/%d/%y %H:%M:%S")

  dt
}

# Use foreach to read all CSV files in parallel
result <- foreach(file = csv_files, .packages = "data.table") %dopar% {
  read_csv_file(file)
}

# Stop
stopCluster(cl)

# Combine the list of data.tables into a single data.table
final_data <- rbindlist(result)

# Check the dimensions of the final_data
print(dim(final_data))

final_data <- final_data %>%
  arrange(datetime) %>%
  mutate(p_mmhr = if_else(p_mmhr < 0, 0, p_mmhr),
         p_mm = p_mmhr*(1/30)) %>%
  dplyr::select(-c(V1, doy, hour, min)) %>%
  rename(MI2_mmhr = p_mmhr)

# Write the combined data to csv
write.csv(final_data, './data/mrms_data/tb_pixels_2023/tb_pixels23.csv')

```

Ran the above for all the groups (2021, 2022, 2022, 2023)

# RQI

Get RQI for TB pixels

```{r}

# Output dir
output_dir <- "./data/mrms_data/RQI/tb_pixel23/"

# raster dir
base_dir <- "./data/mrms_data/RQI/2023/RQI_crop_bbox2fires"

# List raster filenames
filenames <- list.files(base_dir, pattern = ".tif", full.names = FALSE)

# Parallel processing
cl <- makeCluster(4)
registerDoParallel(cl)

# Loop for parallel processing
foreach(fileName = filenames, .packages = c("terra", "lubridate", "dplyr", 'sf', 'tidyverse')) %dopar% {
  
  # Construct full file path
  full_file_path <- file.path(base_dir, fileName)

  tb_all <- read_csv('./data/GIS/tb_locations_new.csv') %>%
  dplyr::select(site, x, y)
  tb_locations <- vect(tb_all, geom = c("x", "y"), crs = "EPSG:4326")
  
  # Pull in raster
  r <- terra::rast(full_file_path)

  names(r) <- "RQI"

  # Extract using terra- zonal stats, weighted mean
  extract <- terra::extract(r, tb_locations)

  extract$site <- tb_locations$site

  timestamp <- substr(fileName, 25, 39)

  # get out of UST to MST
  extract <- extract %>%
    mutate(datetime = ymd_hms(timestamp)) %>%
    mutate(datetime = datetime - (7 * 60 * 60)) %>%
    mutate(doy = yday(datetime),
           hour = hour(datetime),
           min = minute(datetime))

  # Create output filename
  output_filename <- paste0(output_dir, "extract_", extract$doy[1], "_", extract$hour[1], "_", extract$min[1], ".csv")

  write.csv(extract, file = output_filename)

  # Return a message indicating completion
  cat("Data extraction completed for:", fileName, "\n")
}

# Stop parallel processing
stopCluster(cl)

```

## Combine csvs into 1

```{r}

# Location of individual CSVs
csv_directory <- output_dir

# List them
csv_files <- list.files(csv_directory, pattern = "\\.csv$", full.names = TRUE)

# Set cores for parallel processing
cl <- makeCluster(8)
registerDoParallel(cl)

# Function to read CSV files using data.table
read_csv_file <- function(file) {
  dt <- data.table::fread(file, na.strings = c("NA", "NaN", "N/A"))

  # Check if the filename ends with "0_0.csv" and the "datetime" column contains only dates
  if (grepl("0_0.csv$", file) && "datetime" %in% colnames(dt) &&
      all(is.na(as.POSIXct(dt$datetime, format = "%Y-%m-%d %H:%M:%S")))) {
    dt$datetime <- paste0(dt$datetime, " 00:00:00")  # Append "00:00:00" to the datetime
  }

  # Convert the "datetime" column to POSIXct format (consistent date-time format)
  dt$datetime <- as.POSIXct(dt$datetime, format = "%m/%d/%y %H:%M:%S")

  dt
}

# Use foreach to read all CSV files in parallel
result <- foreach(file = csv_files, .packages = "data.table") %dopar% {
  read_csv_file(file)
}

# Stop
stopCluster(cl)

# Combine the list of data.tables into a single data.table
final_data <- rbindlist(result)

# Check the dimensions of the final_data
print(dim(final_data))

final_data <- final_data %>%
  arrange(datetime) %>%
  dplyr::select(-c(V1, doy, hour, min))

# Write the combined data to csv
write.csv(final_data, './data/mrms_data/RQI/tb_pixels23.csv')

```

# Load pixel TB precip and RQI

The next steps:
- Load in and prep the pixel TB mrms data 
- Load in and prep RQI data to be joined with pixel TB data
- Get events & intensities for each pixel (need to add code where it's averaging RQI over the event)
- For TB data, pull time windows that align with mrms, then get the events & intens for that

```{r}

# load in pixel data
pixel21 <- read_csv('./data/mrms_data/tb_pixels_2021/tb_pixels21.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T) 
# stupidly had repeats in the tb pixel lat long file for the pixel extract
# so have to remove the repeats

pixel22 <- read_csv('./data/mrms_data/tb_pixels_2022/tb_pixels22.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

# get rid of lpm and drowsy bc they aren't covered here
pixel23 <- read_csv('./data/mrms_data/tb_pixels_2023/tb_pixels23.csv') %>%
  dplyr::select(-1) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

# bind together all - now I think we want to find the events & intens
pixel <- bind_rows(pixel21, pixel22, pixel23) %>%
  mutate(year = year(datetime))
    
rqi23 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels23.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi22 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels22.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi21 <- read_csv('./data/mrms_data/RQI/rqi_tb_pixels21.csv') %>%
  dplyr::select(3:5) %>%
  force_tz(datetime, tzone = 'MST') %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% (6:9)) %>%
  group_by(datetime, site) %>%
  distinct(., .keep_all = T)

rqi <- bind_rows(rqi23, rqi22, rqi21) %>%
  dplyr::select(-month)

both <- left_join(pixel, rqi, by = c('site','datetime'))

```

# Pixel events
Don't need to run anymore

```{r}

# right now getting it into 10 min timesteps since the smallest MI we do is 10
pixel10 <- both %>%
  mutate(timestamps_10min = ceiling_date(datetime, "10 mins")) %>%
  mutate(RQI = if_else(RQI < 0, 0, RQI)) %>%
  group_by(site, timestamps_10min) %>%
  summarize(rain_mm = sum(p_mm), 
            rqi = mean(RQI, na.rm=T)) %>%
  rename(datetime = timestamps_10min)


get_rqi_events <- function(ID_name) {
  rqi_events <- pixel10 %>%
  filter(site == ID_name,
         rain_mm >= 0.1) %>%
  get_mrms_events(., datetime)
  
  return(rqi_events)
}

# list out sites
sites <- unique(pixel10$site)

# get events for all sites
rqi_events <- map(sites, ~ get_rqi_events(.)) %>%
  bind_rows()

# join this back later by site and event
rqi_mean <- rqi_events %>%
  group_by(site, event) %>%
  summarize(mean_rqi = mean(rqi, na.rm = T))

# list out sites
sites <- unique(pixel10$site)

# get events for all sites
pixel_events <- map(sites, ~ get_mrms_all_events(pixel10, .)) %>%
  bind_rows()

# get intens for all sites
pixel_intens <- map(sites, ~ get_mrms_intensities(pixel_events, .)) %>%
  bind_rows(.)

# pixel_intens <- pixel_intens %>%
#   group_by(site) %>%
#   arrange(event) %>%
#   mutate(event = 1:n()) %>%
#   mutate(year = year(start_time)) #%>%
  # mutate(site = case_when(
  #   site == 'HUm2' ~ 'hum2',
  #   site == 'LPm' ~ 'lpm',
  #   site == 'MUb' ~ 'mub',
  #   site == 'm_e' ~ 'me',
  #   site == 'm_m' ~ 'mm',
  #   site == 'm_w' ~ 'mw',
  #   site == 'u_e' ~ 'ue',
  #   site == 'u_m' ~ 'um',
  #   site == 'u_w' ~ 'uw',
  #   TRUE ~ site))

ggplot(pixel_intens, aes(y=MI60_mmhr, x=site)) + geom_boxplot()
ggplot(pixel_intens, aes(y=event_sum_mm, x=site)) + geom_boxplot()

# write_csv(pixel_intens, './data/final/mrms/pixel_compare/pixel10_events.csv')
# write_csv(rqi_mean, './data/final/mrms/pixel_compare/rqi_events_mean.csv')

pixel_intens <- read_csv('./data/final/mrms/pixel_compare/pixel10_events_ours.csv') %>%
  force_tz(datetime, tzone = 'MST')

```

# Read in TB data

```{r}
# read in tb data
cpf_tb <- read_csv('./data/cpf_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

etf_tb <- read_csv('./data/et_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

ben_tb <- read_csv('./data/bennett_TB_rain.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         p_mm = tip * 0.254) %>%
  mutate(datetime = force_tz(datetime, tzone = 'MST')) %>%
  dplyr::select(-tip)

```

# Read in USGS TB data

```{r}

willow_upper <- readNWISuv(siteNumber = 401642106051601, 
                           parameterCd = "00045") %>% 
  dplyr::select(datetime = 3, P_in = 4) %>% # tz is in UTC
  mutate(p_mm = P_in * 25.4,
         datetime = with_tz(datetime, tzone = 'MST'),
         site = 'willowcr_upper') %>%
  dplyr::select(-P_in)

drowsy <- readNWISuv(siteNumber = 400912106031201, 
                     parameterCd = "00045") %>%
  dplyr::select(datetime = 3, P_in = 4) %>% # tz is in UTC
  mutate(p_mm = P_in * 25.4,
         datetime = with_tz(datetime, tzone = 'MST'),
         site = 'drowsy') %>%
  dplyr::select(-P_in)

usgs <- bind_rows(willow_upper, drowsy)

# now bind all together - select only June - Sept
tb <- bind_rows(cpf_tb, etf_tb, ben_tb, usgs) %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9))

```

# Process TB events -- ONLY NEEDED FOR TESTING WINDOWS

```{r}

load('./R/rain_metrics.RData')

dadd_tb <- read_csv('./data/cpf_TB_rain.csv') %>%
  filter(site == 'dadd') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  arrange(datetime) %>%
  mutate(P_mm = 0.254)

dadd_tb <- get_setup(dadd_tb, dadd_tb$datetime)

dadd_events <- get_events(dadd_tb, dadd_tb$P_mm, dadd_tb$datenumeric,
                          dadd_tb$end, dadd_tb$rain_start)

dadd_events <- get_intensities(dadd_events, dadd_events$event, dadd_tb)

#me 
# me_rain <- get_setup(me_rain, me_rain$datetime)
# me_events <- get_events(me_rain, me_rain$P_mm, me_rain$datenumeric,
#                         me_rain$end, me$rain_start)
# me_events <- get_intensities(me_events, me_events$event, me_rain)

dadd_events <- dadd_events %>%
  mutate(starttime = as.character(starttime),
         endtime = as.character(endtime))

write_csv(dadd_events, './data/final/mrms/pixel_compare/dadd_obs_events.csv')

```

# Filter TB data based on pixel event windows

```{r}

pixel10_intens <- read_csv('./data/final/mrms/pixel_compare/pixel10_events_ours.csv') %>%
  mutate(start_time = with_tz(start_time, 'MST'),
         end_time = with_tz(end_time, 'MST')) %>%
  mutate(site = case_when(
    site == 'HUm2' ~ 'hum2',
    site == 'LPm' ~ 'lpm',
    site == 'MUb' ~ 'mub',
    site == 'm_e' ~ 'me',
    site == 'm_m' ~ 'mm',
    site == 'm_w' ~ 'mw',
    site == 'u_e' ~ 'ue',
    site == 'u_m' ~ 'um',
    site == 'u_w' ~ 'uw',
    TRUE ~ site))
         
site_name <- unique(pixel10_intens$site)

tb_filter <- map_df(site_name, filter_tb) %>% 
  arrange(datetime) 

# filter some things to just see mont to make sure above code is good - ONLY FOR TESTING
# mont_tb <- tb %>%
#   filter(site == 'montgomery')
# 
# mont_pixel <- pixel10_intens %>%
#   filter(site == 'montgomery')

```

# TB filtered (based on pixel events) events

```{r}

# get events for tb_filter
tb_fil10 <- tb_filter %>%
  mutate(timestamps_10min = ceiling_date(datetime, "10 mins")) %>%
  group_by(site, timestamps_10min) %>%
  summarize(rain_mm = sum(p_mm),
            event_mrms = mean(event_mrms)) %>%
  rename(datetime = timestamps_10min) 


sites <- unique(tb_fil10$site)

# get events for all sites
tbfil_events <- map(sites, ~ get_mrms_all_events(tb_fil10, .)) %>%
  bind_rows()

tbfil_intens <- map(sites, ~ get_mrms_intensities(tbfil_events, .)) %>%
  bind_rows()

pixel_intens <- pixel10_intens %>%
  #filter(site == site_name) %>% # update later
  rename(event_mrms = event)

comp_intens <- left_join(pixel_intens, tbfil_intens, by = c('site', 'event_mrms'))

```

# Filter for when no TB data
## ETF

Do ETF first -
Some quick filters:
-ET TBs did not run before 6/20/22 (p1, mub, hum2, lpm)

```{r}

comp_etf <- comp_intens %>%
  filter(site %in% c("p1", "mub", "lpm", "hum2")) %>%
  filter(start_time.x > ymd_hms('2022-06-20 11:00:00', tz = 'MST')) %>%
  mutate(
    condition = case_when(
      site == 'hum2' &
        start_time.x > ymd_hms('2022-08-04 11:16:00', tz = 'MST') ~ 'remove',
      site == 'p1' &
        start_time.x > ymd_hms('2022-07-12 08:36:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-07-21 16:00:00', tz = 'MST') ~ 'remove',
      site == 'p1' &
        start_time.x > ymd_hms('2023-07-21 23:57:00', tz = 'MST') ~ 'remove',
      site == 'lpm' &
        start_time.x > ymd_hms('2022-10-18 10:23:00', tz = 'MST') &
        start_time.x < ymd_hms('2023-05-24 13:20:00', tz = 'MST') ~ 'remove',
      site == 'lpm' &
        start_time.x > ymd_hms('2023-06-11 16:55:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
    )
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

write_csv(comp_etf, './data/final/mrms/pixel_compare/etf_pixel_compare.csv')

# filter <- comp_etf %>%
#   filter(site %in% c('hum2'))

# ggplot(comp_etf, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
#   geom_point() +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
#   geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
#   ggtitle(paste('etf MI60:', paste("R2 =", round(summary(lm(comp_etf$MI60_mmhr.y ~ comp_etf$MI60_mmhr.x, data = comp_etf))$r.squared, digits = 2)))) +
#   labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$MI60_mmhr.y, comp_etf$MI60_mmhr.x)

library(RColorBrewer)

ggplot(comp_etf %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
       aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point(alpha = 0.9, size = 3) +
  scale_color_distiller(palette = "Spectral") +  # Use a continuous ColorBrewer palette
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_etf, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point(aes(#color = rqi > 0.4,
                 alpha=1)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$MI10_mmhr.y, comp_etf$MI10_mmhr.x)

ggplot(comp_etf, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$event_sum_mm.y, comp_etf$event_sum_mm.x)

ggplot(comp_etf, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(comp_etf$MI30_mmhr.y, comp_etf$MI30_mmhr.x)

ggplot(comp_etf, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

```

## Bennett

```{r}

comp_benn <- comp_intens %>%
  filter(site %in% c("mm", "me", "mw", "ue", "um", "uw")) %>%
  mutate(
    condition = case_when(
      site == 'me' &
        start_time.x < ymd_hms('2021-07-19 15:45:00', tz = 'MST') ~ 'remove',
      site == 'me' &
        start_time.x > ymd_hms('2021-10-21 14:00:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-06-16 11:00:00', tz = 'MST') ~ 'remove',
      site == 'me' & 
        start_time.x > ymd_hms('2023-09-07 15:45:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x < ymd_hms('2021-09-06 13:30:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2021-10-12 15:35:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-22 10:00:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2022-06-07 01:25:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-08-10 10:00:00', tz = 'MST') ~ 'remove',
      site == 'mm' &
        start_time.x > ymd_hms('2022-12-15 19:55:00', tz = 'MST') &
        start_time.x < ymd_hms('2023-06-09 09:15:00', tz = 'MST') ~ 'remove',
      site == 'mm' & 
        start_time.x > ymd_hms('2023-09-28 13:10:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x < ymd_hms('2021-08-20 10:50:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x > ymd_hms('2021-10-14 12:42:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-06 12:00:00', tz = 'MST') ~ 'remove',
      site == 'mw' &
        start_time.x > ymd_hms('2022-07-06 12:10:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-08-03 10:15:00', tz = 'MST') ~ 'remove',
      site == 'mw' & 
        start_time.x > ymd_hms('2023-09-19 15:05:00', tz = 'MST') ~ 'remove',
      site == 'ue' &
        start_time.x < ymd_hms('2021-09-06 13:00:00', tz = 'MST') ~ 'remove',
      site == 'ue' &
        start_time.x > ymd_hms('2021-10-12 13:17:00', tz = 'MST') &
        start_time.x < ymd_hms('2022-05-07 12:00:00', tz = 'MST') ~ 'remove',
      site == 'mw' & 
        start_time.x > ymd_hms('2023-05-22 11:33:00', tz = 'MST') ~ 'remove',
      site == 'um' & 
        start_time.x < ymd_hms('2021-07-26 13:30:00', tz = 'MST') ~ 'remove',
      site == 'um' & 
        start_time.x > ymd_hms('2021-07-31 13:32:00', tz = 'MST') ~ 'remove',
      site == 'uw' & 
        start_time.x < ymd_hms('2021-07-19 14:00:00', tz = 'MST') ~ 'remove',
      site == 'um' & 
        start_time.x > ymd_hms('2023-09-07 14:05:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep')) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)
  ) %>%
    filter(!site %in% c('um'))

filter <- comp_benn

cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)

ggplot(filter %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
       aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point(alpha = 0.7, size = 3) +
  scale_color_distiller(palette = "Spectral") +  # Use a continuous ColorBrewer palette
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('benn MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('benn MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)

ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('benn MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)

ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('benn event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)

ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('benn MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

```

Montgomery test

```{r}

comp_mont <- comp_intens %>%
  mutate(condition = case_when(
          site == 'montgomery' &
        start_time.x < ymd_hms('2021-06-11 10:00:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x > ymd_hms('2023-09-19 19:00:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
  ))


ggplot(comp_mont, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('MI60:', paste("R2 =", round(summary(lm(comp_mont$MI60_mmhr.y ~ comp_mont$MI60_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')


ggplot(comp_mont, aes(y = MI10_mmhr.y, x = MI10_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$MI10_mmhr.y ~ comp_mont$MI10_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_mont, aes(y = event_sum_mm.y, x = event_sum_mm.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$event_sum_mm.y ~ comp_mont$event_sum_mm.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(comp_mont, aes(y = MI30_mmhr.y, x = MI30_mmhr.x, color = rqi)) + 
  geom_point() +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("R2 =", round(summary(lm(comp_mont$MI30_mmhr.y ~ comp_mont$MI30_mmhr.x, data = comp_mont))$r.squared, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')


```

## CPF sites

```{r}

comp_cpf <- comp_intens %>%
  filter(site %in% c('aspen', 'bighorn', 'bl4', 'dadd', 'dry', 'michigan', 'montgomery', 'mtcampus')) %>%
  mutate(
    condition = case_when(
      site == 'aspen' &
        start_time.x < ymd_hms('2021-05-18 14:30:00', tz = 'MST') ~ 'remove',
      site == 'aspen' &
        start_time.x > ymd_hms('2021-06-28 11:56:00', tz = 'MST') &
        start_time.x < ymd_hms('2021-10-7 15:00:00', tz = 'MST') ~ 'remove',
      site == 'aspen' &
        start_time.x > ymd_hms('2023-09-21 12:45:00', tz = 'MST') ~ 'remove',
      site == 'bighorn' &
        start_time.x < ymd_hms('2021-05-07 11:20:00', tz = 'MST') ~ 'remove',
      site == 'bl4' &
        start_time.x < ymd_hms('2021-06-11 13:00:00', tz = 'MST') ~ 'remove',
      site == 'bl4' &
        start_time.x > ymd_hms('2023-09-04 14:15:00', tz = 'MST') ~ 'remove',
      site == 'dadd' &
        start_time.x > ymd_hms('2022-05-12 15:00:00', tz = 'MST') ~ 'remove',
      site == 'dry' &
        start_time.x < ymd_hms('2021-05-18 11:15:00', tz = 'MST') ~ 'remove',
      site == 'michigan' &
        start_time.x > ymd_hms('2021-10-24 11:15:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x < ymd_hms('2021-06-11 10:00:00', tz = 'MST') ~ 'remove',
      site == 'montgomery' &
        start_time.x > ymd_hms('2023-09-19 19:00:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
    )
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

filter <- comp_cpf #%>%
  filter(site %in% c('dadd'))

cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)

ggplot(filter %>% arrange(desc(rqi)),  # Arrange data so higher rqi values are plotted first
       aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  geom_point(alpha = 0.7, size = 3) +
  scale_color_distiller(palette = "Spectral") +  # Use a continuous ColorBrewer palette
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x, color = rqi)) + 
  #geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)

ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)

ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)

ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('cpf MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')
```

## ETF USGS

```{r}

comp_usgs <- comp_intens %>%
  filter(site %in% c('willowcr_upper', 'drowsy')) %>%
  mutate(condition = case_when(
      site == 'willowcr_upper' &
        start_time.x < ymd_hms('2022-05-01 05:00:00', tz = 'MST') ~ 'remove',
      site == 'drowsy' &
        start_time.x < ymd_hms('2022-05-19 21:10:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
  ) 
  ) %>%
  filter(condition == 'keep') %>%
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

filter <- comp_usgs #%>%
  filter(site %in% c('drowsy'))

cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)

ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)

ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)

ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)

ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('etf usgs MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

```

# Correlation by site

```{r}
# same window
# write_csv(comp_cpf, './data/final/mrms/pixel_compare/cpf_0window.csv')
# write_csv(comp_etf, './data/final/mrms/pixel_compare/etf_0window.csv')
# write_csv(comp_benn, './data/final/mrms/pixel_compare/benn_0window.csv')
# write_csv(comp_usgs, './data/final/mrms/pixel_compare/usgs_0window.csv')

# combine all 3 to calculate metrics
comp_window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)

# get r2 for each metric 
comp_r2 <- comp_window %>%
  group_by(site) %>%
  summarize(mi60_cor = cor(MI60_mmhr.y, MI60_mmhr.x),
         mi30_cor = cor(MI30_mmhr.y, MI30_mmhr.x),
         mi10_cor = cor(MI10_mmhr.y, MI10_mmhr.x),
         eventsum_cor = cor(event_sum_mm.y, event_sum_mm.x))

# # 15 min both sides
# comp_15window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp15_r2 <- comp_15window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 15)
# 
# # 30 min both sides
# comp_30window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp30_r2 <- comp_30window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 30)
# 
# # 45 min both sides
# comp_45window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp45_r2 <- comp_45window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 45)
# 
# # 60 min both sides
# comp_60window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp60_r2 <- comp_60window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 60)
# 
# # 75 min both sides
# comp_75window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp75_r2 <- comp_75window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 75)
# 
# # 90 min both sides
# comp_90window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp90_r2 <- comp_90window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 90)
# 
# # 105 min both sides
# comp_105window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp105_r2 <- comp_105window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 105)
# 
# # 90 min both sides
# comp_120window <- bind_rows(comp_cpf, comp_benn, comp_etf, comp_usgs)
# 
# # get r2 for each metric 
# comp120_r2 <- comp_120window %>%
#   group_by(site) %>%
#   summarize(mi60_r2 = summary(lm(MI60_mmhr.y ~ MI60_mmhr.x))$r.squared,
#          mi30_r2 = summary(lm(MI30_mmhr.y ~ MI30_mmhr.x))$r.squared,
#          mi10_r2 = summary(lm(MI10_mmhr.y ~ MI10_mmhr.x))$r.squared,
#          eventsum_r2 = summary(lm(event_sum_mm.y ~ event_sum_mm.x))$r.squared) %>%
#   mutate(window = 120)
# 
# comp_windows <- bind_rows(comp0_r2, comp15_r2, comp30_r2, comp45_r2, comp60_r2,
#                           comp75_r2, comp90_r2, comp105_r2, comp120_r2)
# 
# get_window_figs <- function(site_name) {
#   
# comp_site <- comp_windows %>%
#   filter(site == site_name) %>% 
# ggplot(aes(window, mi60_r2, color=site)) + geom_point()
# 
# ggplotly(comp_site)
# 
# }
# 
# site_name <- unique(comp_windows$site)
# 
# map(site_name, get_window_figs)

#write_csv(comp_windows, './data/final/mrms/pixel_compare/compare_windows.csv')

# # how many events have mrms data but no tb data
# notb <- comp_window %>%
#   mutate(missing = if_else(event_sum_mm.y == 0, 1, 0)) %>%
#   summarize(total_events = n(),
#             missing_evnts = sum(missing)) %>%
#   mutate(percent_missing = (missing_evnts / total_events)*100) %>%
#   left_join(., center_dist, by = 'site')
# 
# ggplot(notb, aes(NEAR_DIST, percent_missing)) + geom_point()
# 
# 
# ####################3
# comp_windows_group <- comp_windows %>%
#   group_by(site) %>%
#   summarize(
#     max_mi60_r2 = max(mi60_r2),
#     window_with_max_mi60_r2 = window[which.max(mi60_r2)]
#   )
# 
# 
# ggplot(comp_windows_group, aes(window_with_max_mi60_r2)) + geom_histogram()

```

<!-- # Extracted pixels distance from centroid -->
<!-- wasn't giving accurate results in R so did it in arc gis - csv is in data folder -->

<!-- ```{r} -->

<!-- # distance to centroids -->
<!-- center_dist <- read_csv('./data/tb_mrms_centroid.csv') %>% -->
<!--   select(site, NEAR_DIST) -->

<!-- comp_windows <- left_join(comp_windows, center_dist, by = 'site') -->

<!-- comp_site <- comp_windows %>% -->
<!--   #filter(site == 'drowsy') %>%  -->
<!-- ggplot(aes(window, mi60_r2, color=NEAR_DIST)) + geom_point() -->

<!-- ggplotly(comp_site) -->

<!-- ``` -->

<!-- # Events when there is TB but no MRMS -->

<!-- ```{r} -->

<!-- # same as filter code but put a ! before filter  -->
<!-- filter_tb_nomrms <- function(site_name) { -->
<!--   pixel_site <- pixel_intens %>% -->
<!--     filter(site == site_name) -->

<!--   tb_site <- tb %>% -->
<!--     filter(site == site_name) -->

<!--   tb_site_fil <- map2(pixel_site$start_time, pixel_site$end_time, ~ { -->
<!--     start_time <- .x  -->
<!--     end_time <- .y  -->
<!--     #event <- pixel_site$event[pixel_site$start_time == .x]  # Get corresponding event value - CHANGE THIS BACK TO EVENT -->

<!--     # Filter tb_site for rows where datetime falls between start_time and end_time -->
<!--     tb_site %>% -->
<!--       filter(!between(datetime, start_time, end_time)) #%>% -->
<!--       #mutate(event_mrms = event)  # Add the event column -->
<!--   }) %>% -->
<!--   bind_rows()  # Combine the filtered results -->

<!--   #return(tb_site_fil) -->
<!-- } -->

<!-- site_name <- unique(pixel_intens$site) -->

<!-- tb_noMRMS <- map_df(site_name, filter_tb_nomrms) %>%  -->
<!--   arrange(datetime) -->

<!-- tb_noMRMS <- tb_noMRMS %>% -->
<!--   mutate(month = month(datetime), -->
<!--          year = year(datetime)) %>% -->
<!--   filter(month %in% (5:9), -->
<!--          year %in% c(2021:2023)) -->

<!-- test <- tb_noMRMS %>% filter(site == 'aspen') -->

<!-- # now find events in the tb_nomrms windows -->
<!-- # get events for tb_filter -->
<!-- tb_fil10_nomrms <- tb_noMRMS %>% -->
<!--   mutate(timestamps_10min = ceiling_date(datetime, "10 mins")) %>% -->
<!--   group_by(site, timestamps_10min) %>% -->
<!--   summarize(rain_mm = sum(p_mm)) %>% -->
<!--   rename(datetime = timestamps_10min) -->

<!-- sites <- unique(tb_fil10_nomrms$site) -->

<!-- # get events for all sites -->
<!-- tbfil_nomrms_events <- map(sites, ~ get_mrms_all_events(tb_fil10_nomrms, .)) %>% -->
<!--   bind_rows() -->

<!-- tbfil_nomrms_intens <- map(sites, ~ get_mrms_intensities(tbfil_nomrms_events, .)) %>% -->
<!--   bind_rows() -->



<!-- ``` -->


<!-- # Confusion matrix -->

<!-- ```{r} -->
<!-- library(caret) -->
<!-- library(irr) -->

<!-- # code 0/1 for rain using comp_0window as it was the best based on R2 and histogram -->
<!-- confusion <- comp_0window %>% -->
<!--   mutate(true_label = if_else(event_sum_mm.y > 0, 1, 0), -->
<!--          estimate_label = 1) #%>% -->
<!--   select(true_label, estimate_label)  -->

<!-- conf_matrix <- confusionMatrix(factor(confusion$true_label), factor(confusion$estimate_label)) -->

<!-- ## -->
<!-- true_label_levels <- levels(factor(confusion$true_label)) -->
<!-- estimate_label_levels <- levels(factor(confusion$estimate_label)) -->

<!-- # Combine levels from both true_label and estimate_label -->
<!-- all_levels <- unique(c(true_label_levels, estimate_label_levels)) -->

<!-- # Convert true_label and estimate_label to factors with combined levels -->
<!-- confusion$true_label <- factor(confusion$true_label, levels = all_levels) -->
<!-- confusion$estimate_label <- factor(confusion$estimate_label, levels = all_levels) -->

<!-- # Now, create the confusion matrix -->
<!-- conf_matrix <- confusionMatrix(confusion$estimate_label, confusion$true_label) -->

<!-- print(conf_matrix) -->

<!-- kappa2(conf_matrix) -->

<!-- ``` -->

# Larimer Co data

## Larimer TB

```{r}

lar_tb <- read_csv('./data/larimerco_precip.csv') %>%
  rename(numid = site) %>%
  mutate(datetime = with_tz(DT_mst, 'MST'))
  
lar_meta <- read_csv('./data/GIS/larimer_tb_meta.csv') %>%
  dplyr::select(numid, site = name)

# make it so the larimer tb data has site name
tb <- left_join(lar_tb, lar_meta, by = 'numid')

lar_names <- unique(lar_meta$site)
site_name <- lar_names
  
pixel10_intens <- read_csv('./data/final/mrms/pixel_compare/pixel10_events.csv') %>%
  mutate(start_time = with_tz(start_time, 'MST'),
         end_time = with_tz(end_time, 'MST')) %>%
  filter(site %in% lar_names)

tb_filter <- map_df(site_name, filter_tb) %>% 
  arrange(datetime) # filter tb based on pixel events

###
# get events for tb_filter
tb_fil10 <- tb_filter %>%
  mutate(timestamps_10min = ceiling_date(datetime, "10 mins"),
         p_mm = p_in*25.4) %>%
  group_by(site, timestamps_10min) %>%
  summarize(rain_mm = sum(p_mm),
            event_mrms = mean(event_mrms)) %>%
  rename(datetime = timestamps_10min) 

sites <- unique(tb_fil10$site)

# get events for all sites
tbfil_events <- map(sites, ~ get_mrms_all_events(tb_fil10, .)) %>%
  bind_rows()

tbfil_intens <- map(sites, ~ get_mrms_intensities(tbfil_events, .)) %>%
  bind_rows()

pixel_intens <- pixel10_intens %>%
  #filter(site == site_name) %>% # update later
  rename(event_mrms = event)

comp_intens <- left_join(pixel_intens, tbfil_intens, by = c('site', 'event_mrms'))

##########

filter <- comp_intens %>%
  mutate(condition = case_when(
      site == 'Fort Collins - Gateway Park' &
        start_time.x > ymd_hms('2021-10-01 01:00:00', tz = 'MST') ~ 'remove',
      site == 'Fort Collins - Rustic' &
        start_time.x > ymd_hms('2023-09-13 13:38:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Crown Gulch Headwaters' &
        start_time.x < ymd_hms('2023-06-27 08:59:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Turner Hill Weather' &
        start_time.x < ymd_hms('2023-06-27 16:59:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Tunnel Creek at Hwy 14' &
        start_time.x < ymd_hms('2022-05-31 23:59:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Chambers Resevoir' &
        start_time.x < ymd_hms('2022-06-27 10:42:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Joe Wright Resevoir' &
        start_time.x < ymd_hms('2022-06-14 12:59:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Roaring Creek at Hwy 14' &
        start_time.x < ymd_hms('2021-08-11 10:59:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Long Draw Resevoir' &
        start_time.x < ymd_hms('2022-06-24 09:13:00', tz = 'MST') ~ 'remove',
      site == 'Larimer - Long Draw Resevoir' &
        start_time.x > ymd_hms('2023-06-01 00:00:00', tz = 'MST') &
        start_time.x < ymd_hms('2023-07-10 22:59:00', tz = 'MST') ~ 'remove',
      TRUE ~ 'keep'
  ) 
  ) %>%
  filter(condition == 'keep') %>%
  filter(!site == 'Larimer - North Fork Big Thompson at Storm Mountain Road') %>% 
  mutate(duration_hr.x = as.numeric(duration_hr.x),
         duration_hr.y = as.numeric(duration_hr.y)) %>%
  mutate_at(
    c(
      'MI60_mmhr.y',
      'MI30_mmhr.y',
      'MI20_mmhr.y',
      'MI10_mmhr.y',
      'event_sum_mm.y',
      'duration_hr.y'),
    ~ replace_na(., 0)) %>%
  arrange(start_time.x)

cor_coeff <- cor(filter$MI60_mmhr.y, filter$MI60_mmhr.x)

ggplot(filter, aes(y = MI60_mmhr.y, x = MI60_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('Larimer MI60:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI10_mmhr.y, filter$MI10_mmhr.x)

ggplot(filter, aes(y = MI10_mmhr.y, x = MI10_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('Larimer MI10:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$event_sum_mm.y, filter$event_sum_mm.x)

ggplot(filter, aes(y = event_sum_mm.y, x = event_sum_mm.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('Larimer event sum:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

cor_coeff <- cor(filter$MI30_mmhr.y, filter$MI30_mmhr.x)

ggplot(filter, aes(y = MI30_mmhr.y, x = MI30_mmhr.x)) + 
  geom_point(aes(color = rqi > 0.4)) +
  scale_color_manual(values = c("TRUE" = "darkgreen", "FALSE" = "red")) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "black") +
  geom_text(x = 12, y = 13, label = "1:1", hjust = 0, vjust = 0, color = "black") +
  ggtitle(paste('Larimer MI30:', paste("Correlation =", round(cor_coeff, digits = 2)))) +
  labs(x = 'MRMS', y = 'TB')

# Corr by site
comp_r2 <- filter %>%
  group_by(site) %>%
  summarize(mi60_cor = cor(MI60_mmhr.y, MI60_mmhr.x),
         mi30_cor = cor(MI30_mmhr.y, MI30_mmhr.x),
         mi10_cor = cor(MI10_mmhr.y, MI10_mmhr.x),
         eventsum_cor = cor(event_sum_mm.y, event_sum_mm.x))

# write dates as.character!
filter1 <- filter %>%
  mutate(start_time.x = as.character(start_time.x),
         end_time.x = as.character(end_time.x),
         start_time.y = as.character(start_time.y),
         end_time.y = as.character(end_time.y))


# export larimer tb.pixel event data
write_csv(filter1, './data/final/mrms/pixel_compare/larimer_tbpixel_compare.csv')

```

## Check Larimer TB record

Make this ggplot so I can check dates.

I added these filtered dates above

```{r}

#function to plot all params
plot_params <- function(site_name) {
  {tb %>%
      filter(site == site_name) %>%
      ggplot(aes(x = datetime, y = p_in)) +
      geom_line() + 
      ggtitle(site_name) +
      theme_bw()} %>%
      ggplotly()
}

name <- unique(tb$site)

plots <- lapply(name, plot_params)
plots

```

# Stage

