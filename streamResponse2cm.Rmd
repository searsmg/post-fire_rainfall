---
title: 'Stage Response: 2 cm'
author: "Megan Sears"
date: "`r Sys.Date()`"
output: html_document
---

```{r, include = F}

knitr::opts_chunk$set(echo = F,
                      message = F,
                      fig.width = 12,
                      fig.height = 6)

library(tidyverse)
library(plotly)
library(here)
library(ggplot2); theme_set(theme_bw(base_size = 20,
                                     base_family = "Arial"))
library(zoo)

```

# Stream event IDs

```{r}

# Generate event ID function
generate_event_ids <- function(event_def) {
  event_ids <- integer(length(event_def)) # create vector
  current_id <- 1 # start at 1
  
  for (i in seq_along(event_def)) {
    if (is.na(event_def[i])) {
      event_ids[i] <- NA # Keep NA if event_def is NA
    } else if (i == 1) {
      event_ids[i] <- current_id
    } else {
      prev <- event_def[i - 1]
      curr <- event_def[i]
      
      if ((prev == "diff" & curr == "same") | (prev == "same" & curr == "same")) {
        event_ids[i] <- event_ids[i - 1] # Keep the same event ID as before
      } else {
        current_id <- current_id + 1 # Assign a new event ID
        event_ids[i] <- current_id
      }
    }
  }
  
  event_ids
}

```

# ETF stream events

```{r}

# already offset in 5a_stage_offests code
et_stage <- read_csv('./data/stage/et_stage_corrected.csv') %>%
  dplyr::select(datetime, Stage_fix, site) %>%
  mutate(datetime = with_tz(datetime, tzone = "MST"))

```

## HUM 

```{r}

# Stage adjust based on manual measurements
hum_stage <- et_stage %>%
  filter(site == 'hum') %>% 
  mutate(month = month(datetime),
         year = year(datetime))

# Stage plot
hum_stage_plot <- ggplot(hum_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(hum_stage_plot)

################################################################################
# filter out unwanted months
hum_stage <- hum_stage %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

# find stage events pt 1
filter_hum_stage_events <- hum_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(2),
         end_time = filter_time + hours(3))

# pt 2
filtered_hum_stage <- hum_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_hum_stage_events$start_time, 
        filter_hum_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_hum_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# RBI proxy
rbi <- filtered_hum_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom)%>%
  select(-c(numFinal, denom))

# pt 3 - summary
hum_stage_summ <- filtered_hum_stage %>%
  group_by(event_id) %>%
summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(5,7,9,13,14)) # download spikes or noise

hum_stage_summ <- left_join(hum_stage_summ,
                            rbi,
                            by='event_id')

write_csv(hum_stage_summ,
          './data/final/stageResponse_2cm/hum_stage_events.csv')

```

## P1

```{r}

# Stage adjust based on manual measurements
p1_stage <- et_stage %>%
  filter(site == 'p1') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>% 
  filter(month %in% c(6:9), 
         year %in% c(2021:2023))

################################################################################
# stage plot
p1_stage_plot <- ggplot(p1_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(p1_stage_plot)

################################################################################
# stage events pt 1
filter_p1_stage_events <- p1_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,12) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4), # started as 2
         end_time = filter_time + hours(3))

# pt 2
filtered_p1_stage <- p1_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_p1_stage_events$start_time, 
        filter_p1_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_p1_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
p1_stage_summ <- filtered_p1_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id == c(7,11)) # spikes from downloads

rbi <- filtered_p1_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

p1_stage_summ <- left_join(p1_stage_summ,
                            rbi,
                            by='event_id')

write_csv(p1_stage_summ,
          './data/final/stageResponse_2cm/p1_stage_events.csv')

```

## HM

```{r}
# Offset stage based on manual measurements
hm_stage <- et_stage %>%
  filter(site == 'hm') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>% 
  filter(month %in% c(6:9), 
         year %in% c(2021:2023))

################################################################################
# stage plot
hm_stage_plot <- ggplot(hm_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(hm_stage_plot)

################################################################################

# process stage events pt 1
filter_hm_stage_events <- hm_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix, 2) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_hm_stage <- hm_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_hm_stage_events$start_time, 
        filter_hm_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_hm_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
hm_stage_summ <- filtered_hm_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1,2,3,5,23,24)) # snowmelt or downloads
  
  rbi <- filtered_hm_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

hm_stage_summ <- left_join(hm_stage_summ,
                            rbi,
                            by='event_id')

write_csv(hm_stage_summ,
          './data/final/stageResponse_2cm/hm_stage_events.csv')

```

## MPM

```{r}

# Stage offset based on manual measurements
mpm_stage <- et_stage %>%
  filter(site == 'mpm') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>% 
  filter(month %in% c(6:9), 
         year %in% c(2021:2023)) 

################################################################################
# stage plot
mpm_stage_plot <- ggplot(mpm_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(mpm_stage_plot)

################################################################################
# Process stage events pt 1
filter_mpm_stage_events <- mpm_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_mpm_stage <- mpm_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mpm_stage_events$start_time, 
        filter_mpm_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mpm_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
mpm_stage_summ <- filtered_mpm_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(4,6,18:22,24)) # downloads or snowmelt signal
  
rbi <- filtered_mpm_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mpm_stage_summ <- left_join(mpm_stage_summ,
                            rbi,
                            by='event_id')
 
write_csv(mpm_stage_summ,
          './data/final/stageResponse_2cm/mpm_stage_events.csv')

```

## MUM

```{r}

# Stage offsets based on manual measurements
mum_stage <- et_stage %>%
  filter(site == 'mum') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

################################################################################
mum_stage_plot <- ggplot(mum_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(mum_stage_plot)

################################################################################

# Process stage events - pt 1
filter_mum_stage_events <- mum_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_mum_stage <- mum_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mum_stage_events$start_time, 
        filter_mum_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mum_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
mum_stage_summ <- filtered_mum_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2)
  
  rbi <- filtered_mum_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mum_stage_summ <- left_join(mum_stage_summ,
                            rbi,
                            by='event_id')

write_csv(mum_stage_summ,
          './data/final/stageResponse_2cm/mum_stage_events.csv')

```

## MUB

```{r}

# Stage offsets based on manual measurements
mub_stage <- et_stage %>%
  filter(site == 'mub') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

################################################################################
mub_stage_plot <- ggplot(mub_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(mub_stage_plot)

################################################################################

# Process stage events - pt 1
filter_mub_stage_events <- mub_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,2) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_mub_stage <- mub_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mub_stage_events$start_time, 
        filter_mub_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mub_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
mub_stage_summ <- filtered_mub_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2)
  
rbi <- filtered_mub_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mub_stage_summ <- left_join(mub_stage_summ,
                            rbi,
                            by='event_id')

write_csv(mub_stage_summ,
          './data/final/stageResponse_2cm/mub_stage_events.csv')

```

## P2

```{r}

# Stage offsets based on manual measurements
p2_stage <- et_stage %>%
  filter(site == 'p2') %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023)) %>%
  arrange(datetime)


################################################################################
p2_stage_plot <- ggplot(p2_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(p2_stage_plot)

################################################################################

# Processing stage events - pt 1
filter_p2_stage_events <- p2_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,15) > 1,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(8))

# pt 2
filtered_p2_stage <- p2_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_p2_stage_events$start_time, 
        filter_p2_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_p2_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
p2_stage_summ <- filtered_p2_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(22:41, 47)) # snowmelt signal and noise

rbi <- filtered_p2_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

p2_stage_summ <- left_join(p2_stage_summ,
                            rbi,
                            by='event_id')

write_csv(p2_stage_summ,
          './data/final/stageResponse_2cm/p2_stage_events.csv')

```

## Cameras

lm, lpm, lum, mm

same code for events > 2 cm (mrms paper), no changes

```{r}

# lm2 = lm (lm1 is the one that is pointed down the steep hill)
camera <- read_csv('./data/stage/et_camera_stream_data.csv') %>%
  dplyr::select(date = Date,
                site = Site,
                datetime_min = Time_first_water,
                datetime_peak = Time_peak_water,
                stage_rise_cm) %>%
  drop_na(stage_rise_cm) %>%
  mutate(datetime_min = mdy_hm(paste(date, datetime_min),
                                 tz = 'MST'),
         datetime_peak = mdy_hm(paste(date, datetime_peak),
                                tz = 'MST')) %>%
  filter(stage_rise_cm > 2) %>%
  mutate(site = if_else(site == 'mm', 'mm_et', site)) %>%
  mutate(site = if_else(site == 'lm2', 'lm', site)) %>%
  filter(!site == 'lm1')

write.csv(camera,
          './data/final/stageResponse_2cm/et_camera_events.csv')

```

# CPF

## Aspen

```{r}
# manual stage measurements
manual <- read_csv('./data/field_notes/cpf_fieldnotes.csv') %>%
  filter(site == 'aspen') %>% 
  mutate(datetime = mdy_hms(paste(date, arrival_time),
                            tz='MST')) %>%
  mutate(channel_bed_stage_cm = as.numeric(channel_bed_stage_cm)) %>%
  mutate(channel_bed_stage_cm = if_else(is.na(channel_bed_stage_cm),
                                        0, channel_bed_stage_cm),
         manual_stage_use = as.numeric(manual_stage_cm) - 
           as.numeric(channel_bed_stage_cm))

# aspen raw stage data
aspen <- read_csv('./data/stage/Aspen_stage_composite.CSV') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime),
         month = month(datetime)) %>%
  filter(year %in% c(2021:2023),
         month %in% c(6:9)) %>%
  mutate(Stage_cm = Stage_mm / 10)

# Offset stage data based on manual measurements
aspen_stage <- aspen %>%
  mutate(Stage_fix = Stage_cm + 4) %>% # annual adjustment
  filter(!datetime == ymd_hms('2021-06-14 13:15:00',
                               tz='MST')) %>%
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2021-06-14 13:30:00',
                                                tz='MST'),
                             Stage_fix + 5,
                             Stage_fix)) %>% # download
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2022-01-01 14:00:00',
                                                tz='MST'),
                             Stage_fix - 8,
                             Stage_fix)) %>% # annual adjustment
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2023-01-01 14:00:00',
                                                tz='MST'),
                             Stage_fix + 6,
                             Stage_fix)) %>% # annual adjustment
  filter(!datetime == ymd_hms('2023-05-25 10:00:00'))
  
################################################################################
# stage plot
aspen_stage_plot <- ggplot() +
  geom_line(data = aspen_stage, 
            aes(x = datetime, y = Stage_fix)) +
  geom_point(data = manual,
             aes(x = datetime, 
                 y = as.numeric(manual_stage_use)),
             color = 'red')


ggplotly(aspen_stage_plot)

################################################################################
# remove unwanted months and years
aspen_stage <- aspen_stage %>% 
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))
  
# Process stage events pt 1
filter_aspen_stage_events <- aspen_stage %>%
  mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix, 6) > 1,
                            'increase', 'none')) %>% 
   # mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix) > 1.5,
   #                          'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(4))

# pt 2
filtered_aspen_stage <- aspen_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_aspen_stage_events$start_time, 
        filter_aspen_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_aspen_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3 - summary
aspen_stage_summ <- filtered_aspen_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(5,8:12))

rbi <- filtered_aspen_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

aspen_stage_summ <- left_join(aspen_stage_summ,
                            rbi,
                            by='event_id')

write_csv(aspen_stage_summ,
          './data/final/stageResponse_2cm/aspen_stage_events.csv')


```

## Bighorn

```{r}

bighorn_stage <- read_csv('./data/stage/bighorn_stage_composite_new.csv') %>%
  mutate(datetime = mdy_hm(DateTime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023)) %>%
  dplyr::rename(Pw_kPa = 2)

bighorn_baro <- read_csv('./data/stage/bighorn_baro_composite_new.csv') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023)) %>%
  dplyr::rename(Pa_kPa = 2)

bighorn_stage <- left_join(bighorn_stage, bighorn_baro, by = 'datetime') %>%
  mutate(stage_kPa = Pw_kPa - Pa_kPa) %>%
  mutate(stage_cm = (stage_kPa*101.97162129779)/10) %>%
  select(datetime, stage_cm)

# Quinn's stage adjustments below
#correct stage based on manual stage measurements
bighorn_stage<-mutate(bighorn_stage, stage_corr_cm = stage_cm-1)

#offset adjust break in the data
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2021-05-07 12:00:00'),
                                   bighorn_stage$stage_corr_cm+3,bighorn_stage$stage_corr_cm)

##### new adjustments under this line #####

#offset adjust for download
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2022-05-03 14:00:00'),
                                   bighorn_stage$stage_corr_cm+1.5,bighorn_stage$stage_corr_cm)

#offset adjust for download
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2022-05-19 12:45:00'),
                                   bighorn_stage$stage_corr_cm+2,bighorn_stage$stage_corr_cm)

#offset adjust for download
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2022-07-26 13:15:00'),
                                   bighorn_stage$stage_corr_cm-5.5,bighorn_stage$stage_corr_cm)

#offset adjust between 2022 -2023
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2022-12-22 05:00:00'),
                                    bighorn_stage$stage_corr_cm+1.5,bighorn_stage$stage_corr_cm)

#bed elevation adjustment after storm peak
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2023-06-08 09:30:00'),
                                   bighorn_stage$stage_corr_cm-3.3,bighorn_stage$stage_corr_cm)

#offset adjust for download
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2023-06-16 10:15:00'),
                                   bighorn_stage$stage_corr_cm-0.5,bighorn_stage$stage_corr_cm)

# #offset adjust for download
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2023-06-27 10:45:00'),
                                    bighorn_stage$stage_corr_cm-1.2,bighorn_stage$stage_corr_cm)

#bed appears to aggrade after rain on 8/24/23, move stage down
bighorn_stage$stage_corr_cm=ifelse(bighorn_stage$datetime >ymd_hms('2023-08-24 13:45:00'),
                                   bighorn_stage$stage_corr_cm-1,bighorn_stage$stage_corr_cm)

#delete sensor spikes
bighorn_stage$stage_corr_cm = ifelse(bighorn_stage$datetime == ymd_hms('2022-05-19 12:30:00'),
                                     NA, bighorn_stage$stage_corr_cm)

bighorn_stage$stage_corr_cm = ifelse(bighorn_stage$datetime == ymd_hms('2023-06-27 11:00:00'),
                                     NA, bighorn_stage$stage_corr_cm)

################################################################################

bighorn_stage_plot <- ggplot(bighorn_stage, aes(datetime, stage_corr_cm)) +
  geom_line()

ggplotly(bighorn_stage_plot)

################################################################################
# Remove unwanted months
bighorn_stage <- bighorn_stage %>% 
  rename(Stage_fix = stage_corr_cm) %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9))

## Processing stage events - pt 1
filter_bighorn_stage_events <- bighorn_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix, 2) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_bighorn_stage <- bighorn_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_bighorn_stage_events$start_time, 
        filter_bighorn_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_bighorn_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
bighorn_stage_summ <- filtered_bighorn_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(4:14,16,21:23))
  
rbi <- filtered_bighorn_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

bighorn_stage_summ <- left_join(bighorn_stage_summ,
                            rbi,
                            by='event_id')

write_csv(bighorn_stage_summ,
          './data/final/stageResponse_2cm/bighorn_stage_events.csv')


```

## BL4

```{r}

bl4_stage <- read_csv('./data/stage/bl4_stage_composite.csv') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023)) %>%
  mutate(Stage_cm = Stage_mm / 10)

## Code below is Quinn's offsets
bl4_stage$Stage_corr_cm = bl4_stage$Stage_cm + 4.5

#offset adjust for download
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2021-06-11 12:30:00'),
  bl4_stage$Stage_corr_cm + 7.9,
  bl4_stage$Stage_corr_cm
)

#offset adjust for download
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2021-08-06 08:30:00'),
  bl4_stage$Stage_corr_cm + 0.5,
  bl4_stage$Stage_corr_cm
)

#delete sensor spike
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime == ymd_hms('2021-08-06 08:45:00'),
  NA,
  bl4_stage$Stage_corr_cm
)

#offset adjust for download
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2021-08-27 09:00:00'),
  bl4_stage$Stage_corr_cm - 0.3,
  bl4_stage$Stage_corr_cm
)

##### new adjustments under this line #####

#2021-2022 year adjustment
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2021-10-25 11:00:00'),
  bl4_stage$Stage_corr_cm + 2,
  bl4_stage$Stage_corr_cm
)

# disturbance between 5/28/22 and 6/10/22, adjust stage to manual after
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-06-10 14:00:00'),
  bl4_stage$Stage_corr_cm - 15,
  bl4_stage$Stage_corr_cm
)

#delete sensor spike
bl4_stage$Stage_corr_cm = ifelse((
  bl4_stage$datetime >= ymd_hms('2022-07-08 10:45:00') &
    bl4_stage$datetime <= ymd_hms('2022-07-08 11:00:00')
),
NA,
bl4_stage$Stage_corr_cm
)

# 7/8/22, offset adjust download
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-07-08 11:00:00'),
  bl4_stage$Stage_corr_cm + 2.5,
  bl4_stage$Stage_corr_cm
)

# #between 7/8/22 and 10/7/22 (maybe on 8/10/22, 9/15/22, 9/21/22, and 9/29), bed aggrades. Move stage down
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-08-10 10:00:00'),
  bl4_stage$Stage_corr_cm - 1,
  bl4_stage$Stage_corr_cm
)

bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-09-16 12:15:00'),
  bl4_stage$Stage_corr_cm - 1,
  bl4_stage$Stage_corr_cm
)

bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-09-21 16:15:00'),
  bl4_stage$Stage_corr_cm - 1,
  bl4_stage$Stage_corr_cm
)

bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2022-09-29 13:00:00'),
  bl4_stage$Stage_corr_cm - 1,
  bl4_stage$Stage_corr_cm
)
# #2022-2023 year adjustment
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2023-01-01 01:00:00'),
  bl4_stage$Stage_corr_cm + 3,
  bl4_stage$Stage_corr_cm
)

#6/26/23 offset adjust for download
bl4_stage$Stage_corr_cm = ifelse(
  bl4_stage$datetime > ymd_hms('2023-06-26 12:00:00'),
  bl4_stage$Stage_corr_cm - 0.8,
  bl4_stage$Stage_corr_cm
)

#delete data between 5/28/22 and 6/10/22-- mass movement of sediment
bl4_stage$Stage_corr_cm = ifelse((
  bl4_stage$datetime > ymd_hms('2022-05-28 00:00:00') &
    bl4_stage$datetime <= ymd_hms('2022-06-10 14:00:00')
),
NA,
bl4_stage$Stage_corr_cm
)

#delete sensor spike
bl4_stage$Stage_corr_cm = ifelse((
  bl4_stage$datetime >= ymd_hms('2023-08-03 00:00:00') &
    bl4_stage$datetime <= ymd_hms('2023-08-03 00:45:00')
),
NA,
bl4_stage$Stage_corr_cm
)

################################################################################

bl4_stage_plot <- ggplot(bl4_stage, aes(datetime, Stage_corr_cm)) +
  geom_line()

ggplotly(bl4_stage_plot)

################################################################################
# Remove unwanted months
bl4_stage <- bl4_stage %>% 
  rename(Stage_fix = Stage_corr_cm) %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9))

## Processing stage events - pt 1
filter_bl4_stage_events <- bl4_stage %>%
  mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix, 8) > 0.5,
                            'increase', 'none')) %>% 
   # mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix) > 1,
   #                          'increase', 'none')) %>% # if it increases by XX amount
  filter(pos_diff == 'increase') %>% # keep only the increases
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>% # find the diff between current and i-1
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>% # if the diff is > 360 per row then diff event
  mutate(event_id = generate_event_ids(event_def)) %>% # create the event IDs, give new # based on diff and same
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>% # use the smallest timestep between in the event
  mutate(start_time = filter_time - hours(4), # go back 4 hours
         end_time = filter_time + hours(3)) # add 3 hours

# pt 2 - filter based on start and end times above
filtered_bl4_stage <- bl4_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_bl4_stage_events$start_time, 
        filter_bl4_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_bl4_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
bl4_stage_summ <- filtered_bl4_stage %>%
  group_by(event_id) %>% 
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1:11,45:48, 62:75,88)) # mostly early June events (snowmelt) and sensor spike

rbi <- filtered_bl4_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

bl4_stage_summ <- left_join(bl4_stage_summ,
                            rbi,
                            by='event_id')

write_csv(bl4_stage_summ,
          './data/final/stageResponse_2cm/bl4_stage_events.csv')

```

## Dadd

```{r}
# manual stage measurements
manual <- read_csv('./data/field_notes/cpf_fieldnotes.csv') %>%
  filter(site == 'dadd') %>% 
  mutate(datetime = mdy_hms(paste(date, arrival_time),
                            tz='MST')) %>%
  mutate(channel_bed_stage_cm = 
           as.numeric(channel_bed_stage_cm)) %>%
  mutate(channel_bed_stage_cm = 
           if_else(is.na(channel_bed_stage_cm),
                                        0, channel_bed_stage_cm),
         manual_stage_use = as.numeric(manual_stage_cm) - 
           as.numeric(channel_bed_stage_cm))

dadd <- read_csv('./data/stage/Dadd_stage_composite.csv') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023)) %>%
  mutate(Stage_cm = Stage_mm / 10)

################################################################################
# Stage offsets
dadd_stage <- dadd %>%
  mutate(Stage_fix = Stage_cm + 5) %>% # annual
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2021-04-25 18:45:00',
                                                tz='MST'),
                             Stage_fix + 5,
                             Stage_fix)) %>% # annual 
  filter(!datetime == ymd_hms('2021-06-14 11:30:00',
                              tz = 'MST')) %>% 
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2022-02-22 11:00:00',
                                                tz='MST'),
                             Stage_fix - 3,
                             Stage_fix)) # download
# ignoring 5/26/22 manual stage measurement - seems like too much bed change

################################################################################

dadd_stage_plot <- ggplot() +
  geom_line(data = dadd_stage, 
            aes(x = datetime, y = Stage_fix)) +
  geom_point(data = manual,
             aes(x = datetime, 
                 y = as.numeric(manual_stage_use)),
             color = 'red')

ggplotly(dadd_stage_plot)

################################################################################
# Filter unwanted data
dadd_stage <- dadd_stage %>% 
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

## Processing stage events - pt 1
filter_dadd_stage_events <- dadd_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,8) > 0.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(8))

# pt 2
filtered_dadd_stage <- dadd_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_dadd_stage_events$start_time, 
        filter_dadd_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_dadd_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
dadd_stage_summ <- filtered_dadd_stage %>%
  group_by(event_id) %>%  
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(5,32:48)) # noise
  
rbi <- filtered_dadd_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

dadd_stage_summ <- left_join(dadd_stage_summ,
                            rbi,
                            by='event_id')

write_csv(dadd_stage_summ,
          './data/final/stageResponse_2cm/dadd_stage_events.csv')

```

## Dry

-Had to change from 1.5 to 2 increase bc it was starting an invite too early
2022-07-05

```{r}

dry_stage <- read_csv('./data/stage/Dry_stage_composite_pt.csv') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023))

# from Quinn's code
dry_stage$datetime = round_date(dry_stage$datetime, unit = "5 mins")
dry_stage <- filter(dry_stage, duplicated(datetime)==FALSE)

dry_baro <- read_csv('./data/stage/Dry_baro_composite.csv') %>%
  mutate(datetime = mdy_hm(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023))

# below code is from Quinn's offsets
bighorn_baro <- read_csv('./data/stage/bighorn_baro_composite_new.csv') %>%
  rename(Pa_kPa = 2) %>%
  mutate(Pa_psi=(Pa_kPa/6.89476)+0.3) %>% # 0.3 adjustment to match dry
  mutate(datetime = mdy_hm(datetime, tz = "MST")) %>%
  filter(datetime >= ymd_hms("2020-12-19 00:00:00"))

dry_stage_pt_before<- dry_stage %>%
  filter(datetime < ymd_hms('2023-07-13 10:45:00'))

dry_stage_pt_after<- dry_stage %>%
  filter(datetime > ymd_hms('2023-07-13 10:45:00'))

dry_baro_before <-dry_baro %>%
  filter(datetime < ymd_hms('2023-07-13 10:45:00'))

dry_baro_after <- bighorn_baro %>%
  filter(datetime > ymd_hms('2023-07-13 10:45:00'))

merged_data_before <-full_join(dry_stage_pt_before, dry_baro_before, by='datetime') %>%
  select(datetime, Pa_psi, Pw_psi)
merged_data_after <- full_join(dry_stage_pt_after,dry_baro_after, by='datetime') %>%
  select(datetime, Pa_psi, Pw_psi)
dry_stage=rbind(merged_data_before, merged_data_after)

# fill in baro data where pt was recorded at shorter time interval (from QM code)
dry_stage$Pa_psi<-na.locf(dry_stage$Pa_psi)

dry_stage <- dry_stage %>%
  mutate(stage_psi = Pw_psi - Pa_psi) %>%
  mutate(Stage_cm = stage_psi*70.307) %>%
  select(datetime, Stage_cm) %>%
  filter(!is.na(Stage_cm))

# again, all below code is from QM
#correct stage based on manual stage measurements
#bed adjustments from SK's code data_processing_all
dry_stage<-mutate(dry_stage, stage_corr_cm = Stage_cm)

#offset adjust sensor stage to levels of manual stage
#4/1 data download offset
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-04-01 09:30:00'),
  dry_stage$stage_corr_cm + 1,
  dry_stage$stage_corr_cm
)

#4/4/21, bed incised, move stage up
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-04-03 20:00:00'),
  dry_stage$stage_corr_cm + 4.5,
  dry_stage$stage_corr_cm
)

#4/19/21, scouring, bed incised. move stage up
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-04-19 12:00:00'),
  dry_stage$stage_corr_cm + 5,
  dry_stage$stage_corr_cm
)

#do not see evidence of the scouring for 4/29 and 5/6. or the aggradation before 5/18

#offset adjusting 5/6 for download
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-05-06 12:45:00'),
  dry_stage$stage_corr_cm - 2.5,
  dry_stage$stage_corr_cm
)

# #offset adjusting 5/18 for download
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-05-18 11:30:00'),
  dry_stage$stage_corr_cm + 4,
  dry_stage$stage_corr_cm
)

# #5/23/21, scouring, bed incised, but manual stage after is lower. move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-05-23 00:00:00'),
  dry_stage$stage_corr_cm - 1,
  dry_stage$stage_corr_cm
)

#6/25/21, bed aggrades. move stage down.
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-06-26 00:00:00'),
  dry_stage$stage_corr_cm - 8,
  dry_stage$stage_corr_cm
)

#6/30/21, data download offset. move stage down.
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-06-30 11:30:00'),
  dry_stage$stage_corr_cm - 8,
  dry_stage$stage_corr_cm
)

#7/21/21, bed incises. move stage up
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-07-20 15:00:00'),
  dry_stage$stage_corr_cm + 6.5,
  dry_stage$stage_corr_cm
)

#7/26/21, data download offset. move stage down.
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-07-26 15:00:00'),
  dry_stage$stage_corr_cm - 6,
  dry_stage$stage_corr_cm
)

#7/30/21, bed incises. move stage up
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-07-30 12:00:00'),
  dry_stage$stage_corr_cm + 10,
  dry_stage$stage_corr_cm
)

#8/16/21, data download offset. move stage down.
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2021-08-16 09:00:00'),
  dry_stage$stage_corr_cm - 2,
  dry_stage$stage_corr_cm
)

##### new adjustments under this line #####

#2021-2022 year adjustment
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2022-02-02 12:00:00'),
  dry_stage$stage_corr_cm - 1,
  dry_stage$stage_corr_cm
)

#5/12/22 offset adjust for download
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2022-05-12 11:00:00'),
  dry_stage$stage_corr_cm + 1,
  dry_stage$stage_corr_cm
)

#between 5/18/22 and 5/25/22, bed aggrades. move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2022-05-25 11:00:00'),
  dry_stage$stage_corr_cm - 1.5,
  dry_stage$stage_corr_cm
)

# #after peak flow on 7/6/22, bed aggrades. Move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms("2022-07-06 14:25:00"),
  dry_stage$stage_corr_cm - 8,
  dry_stage$stage_corr_cm
)

# 7/18/22, stage is 3 and offset adjust for download
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms("2022-07-18 11:45:00"),
  dry_stage$stage_corr_cm - 9,
  dry_stage$stage_corr_cm
)

# weird data between 8/522 and 8/15/22, delete
dry_stage$stage_corr_cm = ifelse((
  dry_stage$datetime > ymd_hms("2022-08-05 09:05:00") &
    dry_stage$datetime < ymd_hms("2022-08-15 21:30:00")
),
NA,
dry_stage$stage_corr_cm
)

#between 8/5/22 and 8/15/22, adjustments to the position of the sensors
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2022-08-15 21:00:00'),
  dry_stage$stage_corr_cm + 10.5,
  dry_stage$stage_corr_cm
)

# 8/29/22 sediment removed from the sensor, adjustment to stage
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2022-08-29 10:00:00'),
  dry_stage$stage_corr_cm + 6,
  dry_stage$stage_corr_cm
)

#2022-2023 year adjustment
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2023-05-04 10:00:00'),
  dry_stage$stage_corr_cm + 12,
  dry_stage$stage_corr_cm
)

# #between 5/4/23 and 5/25/23, bed aggrades. move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2023-05-05 19:30:00'),
  dry_stage$stage_corr_cm - 5,
  dry_stage$stage_corr_cm
)

#between 5/25/23 and 6/7/23, bed aggrades (maybe after peak on 6/6/23). move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2023-06-06 14:25:00'),
  dry_stage$stage_corr_cm - 1.5,
  dry_stage$stage_corr_cm
)

#between 5/25/23 and 6/7/23, bed aggrades after peak on 6/11/23). move stage down
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2023-06-11 15:50:00'),
  dry_stage$stage_corr_cm - 1.5,
  dry_stage$stage_corr_cm
)


# 7/13/2023, switch to Bighorn baro. adjust stage
dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime == ymd_hms('2023-07-13 10:50:00'),
  NA,
  dry_stage$stage_corr_cm
)

dry_stage$stage_corr_cm = ifelse(
  dry_stage$datetime > ymd_hms('2023-07-13 10:50:00'),
  dry_stage$stage_corr_cm - 5.4,
  dry_stage$stage_corr_cm
)

#delete sensor spikes
#data between 8/5/22 and 8/15/22 no good, delete

dry_stage <- dry_stage %>%
  filter(!(
    datetime > ymd_hms("2022-02-02 07:00:00") &
      datetime < ymd_hms("2022-03-20 08:55:00")
  )) %>%
  filter(!(
    datetime > ymd_hms("2022-11-12 16:00:00") &
      datetime < ymd_hms("2023-05-04 12:00:00")
  ))

################################################################################
manual <- read_csv('./data/field_notes/cpf_fieldnotes.csv') %>%
  filter(site == 'dry') %>% 
  mutate(datetime = mdy_hms(paste(date, arrival_time),
                            tz='MST')) %>%
  mutate(channel_bed_stage_cm = as.numeric(channel_bed_stage_cm)) %>%
  mutate(channel_bed_stage_cm = if_else(is.na(channel_bed_stage_cm),
                                        0, channel_bed_stage_cm),
         manual_stage_use = as.numeric(manual_stage_cm) - 
           as.numeric(channel_bed_stage_cm))

dry_stage_plot <- ggplot(dry_stage, aes(datetime, stage_corr_cm)) +
  geom_line() +
  geom_point(data = manual, aes(datetime, manual_stage_use), color='red')

ggplotly(dry_stage_plot)

################################################################################
# Remove unwanted months
dry_stage <- dry_stage %>% 
  rename(Stage_fix = stage_corr_cm) %>%
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

## Processing stage events - pt 1
filter_dry_stage_events <- dry_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix) > 2,
                             # here I'm using 2 bc it starts an event too early (too sensitive)
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_dry_stage <- dry_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_dry_stage_events$start_time, 
        filter_dry_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_dry_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
dry_stage_summ <- filtered_dry_stage %>%
  group_by(event_id) %>%  
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1,2,4,5,9,12,13,14,17,18,
                          19,20,22,23,24,25,26,29,30,35,36,39,40))
  
rbi <- filtered_dry_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

dry_stage_summ <- left_join(dry_stage_summ,
                            rbi,
                            by='event_id')

write_csv(dry_stage_summ,
          './data/final/stageResponse_2cm/dry_stage_events.csv')

```

## Michigan

```{r}
# from usgs gauge
mich <- read_csv('./data/stage/michigan_stage.csv') %>%
  mutate(datetime2 = mdy_hm(dt_use),
         Stage_cm = stage_ft * 30.48) %>%
  select(datetime2, Stage_cm) %>%
  rename(datetime = datetime2)

mich_stage_plot <- ggplot(mich, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(mich_stage_plot)

################################################################################
# Remove unwanted months
mich_stage <- mich %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2023))

# Processing stage events - pt 1
filter_mich_stage_events <- mich_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,12) > 1.0,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(10)) # changed this bc it was missing a slow peak when there were two peaks

# pt 2
filtered_mich_stage <- mich_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mich_stage_events$start_time, 
        filter_mich_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mich_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
mich_stage_summ <- filtered_mich_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1:20, 34:63, 76:108)) # snowmelt signal
  
rbi <- filtered_mich_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mich_stage_summ <- left_join(mich_stage_summ,
                            rbi,
                            by='event_id')

write_csv(mich_stage_summ,
          './data/final/stageResponse_2cm/michigan_stage_events.csv')

```

## Montgomery

```{r}

mont_stage <- read_csv('./data/stage/montgomery_stage_composite.csv') %>%
  select(1,4) %>%
  mutate(datetime = mdy_hm(DateTime, tz='MST')) %>% 
  mutate(Stage_cm = Stage_mm/10) %>%
  mutate(month = month(datetime)) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023))

# below is code from QM
#offset-adjust sensor stage to levels of manual stage
mont_stage$stage_corr_cm = mont_stage$Stage_cm + 5

#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2021-06-11 10:00:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm + 9.3,
  mont_stage$stage_corr_cm
)

#8/2/21, big storm moves sensor. move stage down.
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2021-08-02 16:45:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm - 11.5,
  mont_stage$stage_corr_cm
)

#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2021-08-05 13:00:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm + 10,
  mont_stage$stage_corr_cm
)

#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2021-08-27 13:30:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm - 2,
  mont_stage$stage_corr_cm
)

##### new adjustments under this line #####

#adjustment between 2021 and 2022
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2022-06-01 01:00:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm - 0.5,
  mont_stage$stage_corr_cm
)

#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2022-07-08 09:30:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm + 1,
  mont_stage$stage_corr_cm
)

#adjust to bed change after big April 2023 spike
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2023-04-12 13:00:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm - 4.5,
  mont_stage$stage_corr_cm
)

#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2023-06-20 09:30:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm + 0.9,
  mont_stage$stage_corr_cm
)
#offset adjust for download
mont_stage$stage_corr_cm = ifelse(
  mont_stage$datetime > ymd_hms('2023-06-26 10:00:00', 
                                tz = 'MST'),
  mont_stage$stage_corr_cm + 1.5,
  mont_stage$stage_corr_cm
)

#delete sensor spikes
mont_stage <- mont_stage %>%
  filter(!(
    datetime > ymd_hms('2023-08-25 23:45:00', 
                                tz = 'MST') &
      datetime < ymd_hms('2023-09-03 01:15:00', 
                                tz = 'MST')
  ))

################################################################################

mont_stage_plot <- ggplot(mont_stage, aes(datetime, stage_corr_cm)) +
  geom_line()

ggplotly(mont_stage_plot)

###########################################

# Remove unwanted months 
mont_stage <- mont_stage %>% 
  rename(Stage_fix = stage_corr_cm) %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9)) %>%
  arrange(datetime)

# Processing stage events - pt 1
filter_mont_stage_events <- mont_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(5),
         end_time = filter_time + hours(3))

# pt 2
filtered_mont_stage <- mont_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mont_stage_events$start_time, 
        filter_mont_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mont_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
mont_stage_summ <- filtered_mont_stage %>%
  group_by(event_id) %>%  
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1:11,22,
                          26:42,48,51,54,59,63,
                          65:85,87,93,97,98)) # noise, snowmelt signal, and odd spikes
  
rbi <- filtered_mont_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mont_stage_summ <- left_join(mont_stage_summ,
                            rbi,
                            by='event_id')


write_csv(mont_stage_summ,
          './data/final/stageResponse_2cm/mont_stage_events.csv')

```

## Mt. Campus

```{r}

mtcamp <- read_csv('./data/stage/mtcampus_stage_composite.csv') %>%
  mutate(datetime = mdy_hm(Date_time)) %>%
  rename(Stage_cm = stage_cm) %>%
  select(-Date_time) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023))

# manual stage measurements - from Kira's google drive spreadsheet
mtc_manual <- read_csv('./data/stage/mt_camps_manual_stage.csv') %>%
  mutate(datetime = mdy_hm(datetime, tz='MST')) %>%
  select(datetime, stage_adjusted_cm) %>%
  mutate(year = year(datetime)) %>%
  filter(year %in% c(2021:2023))

mtcamp_stage <- mtcamp %>%
  mutate(Stage_fix = Stage_cm + 12) %>%  # annual adjustment
  mutate(Stage_fix = if_else(datetime >= ymd_hms('2021-07-07 15:30:00',
                                                tz='MST'), # event during snowmelt
                             Stage_fix + 6,
                             Stage_fix),
         Stage_fix = if_else(datetime >= ymd_hms('2022-04-27 01:00:00',
                                                tz='MST'), # annual adjustment
                             Stage_fix - 2,
                             Stage_fix),
         Stage_fix = if_else(datetime >= ymd_hms('2023-04-26 01:00:00',
                                                tz='MST'), # annual adjustment, more to match 6/7/23 download
                             Stage_fix + 2,
                             Stage_fix))

################################################################################         
mtcamp_stage_plot <- ggplot(mtcamp_stage, aes(datetime, Stage_fix)) +
  geom_line() +
  geom_point(data = mtc_manual,
             aes(datetime, stage_adjusted_cm),
             color = 'blue')


ggplotly(mtcamp_stage_plot)

################################################################################

# Remove unwanted months
mtcamp_stage <- mtcamp_stage %>%
  mutate(month = month(datetime)) %>%
  filter(month %in% c(6:9))

# Processing stage events - pt 1
filter_mtcamp_stage_events <- mtcamp_stage %>%
   mutate(pos_diff = if_else(Stage_fix - lag(Stage_fix,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(10))

# pt 2
filtered_mtcamp_stage <- mtcamp_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mtcamp_stage_events$start_time, 
        filter_mtcamp_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mtcamp_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
mtcamp_stage_summ <- filtered_mtcamp_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1:25, 32:48, 50, 54:70)) # snowmelt signal, 50 is noise

# manully adding 2022-08-15 second event in
# start 2022-08-15 13:30, 29.12
# peak 2022-08-15 20:30, 33.19
# had to manually calculate rbi too
  
rbi <- filtered_mtcamp_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mtcamp_stage_summ <- left_join(mtcamp_stage_summ,
                            rbi,
                            by='event_id')

write_csv(mtcamp_stage_summ,
          './data/final/stageResponse_2cm/mtcamp_stage_events.csv')


```

## Washout

```{r}
# From Larimer County
washout <- read_csv('./data/stage/larimer_washout_stage.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         Stage_cm = stage_ft * 30.48)

wash_stage <- washout

# Below are QM's Larimer Co Washout stage offsets
##adjust county data to levels we recorded
wash_stage$stage_corr_cm = wash_stage$Stage_cm - 8

#bed aggrades after 7/20/21 storm, adjust bed down
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2021-07-20 21:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm - 3,
  wash_stage$stage_corr_cm
)

#appears to be data download on 7/29/21, adjust bed down
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2021-07-29 12:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm - 1.5,
  wash_stage$stage_corr_cm
)

#adjust between 2021 and 2022
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2022-05-13 19:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm + 0.4,
  wash_stage$stage_corr_cm
)

#between 5/26/22 and 7/18/22 bed incises. move stage up on 6/13 and after 7/6 peak
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2022-06-13 12:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm + 1.8,
  wash_stage$stage_corr_cm
)

wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2022-07-06 22:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm + 1.1,
  wash_stage$stage_corr_cm
)

#jump in stage on 7/29/22, adjust down
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2022-07-29 11:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm - 3.1,
  wash_stage$stage_corr_cm
)

#bed appears to aggrade after 8/2/23 storm, adjust stage down
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime > ymd_hms('2023-08-02 18:00:00',
                                tz='MST'),
  wash_stage$stage_corr_cm - 1,
  wash_stage$stage_corr_cm
)
#delete sensor spikes
wash_stage$stage_corr_cm = ifelse(
  wash_stage$datetime == ymd_hms('2023-06-19 12:39:00',
                                 tz='MST'),
  NA,
  wash_stage$stage_corr_cm
)

wash_stage$stage_corr_cm = ifelse((
  wash_stage$datetime > ymd_hms('2021-10-19 10:00:00',
                                tz='MST') &
    wash_stage$datetime < ymd_hms('2021-10-19 21:00:00',
                                  tz='MST')
),
NA,
wash_stage$stage_corr_cm
)


wash_stage <- wash_stage %>%
  rename(Stage_fix = stage_corr_cm) %>%
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(year %in% c(2021:2022)) # QM said not to use 2023

################################################################################
washout_stage_plot <- ggplot(wash_stage, aes(datetime, Stage_fix)) +
  geom_line()

ggplotly(washout_stage_plot)

################################################################################

# Remove unwanted data
washout_stage <- wash_stage %>% 
  mutate(month = month(datetime),
         year = year(datetime)) %>%
  filter(month %in% c(6:9),
         year %in% c(2021:2022)) # QM said not to use 2023

# Processing stage events - pt 1
filter_washout_stage_events <- washout_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_washout_stage <- washout_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_washout_stage_events$start_time, 
        filter_washout_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_washout_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
washout_stage_summ <- filtered_washout_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_fix),
          datetime_peak = datetime[which.max(Stage_fix)],
          # Filter Stage_fix values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_fix[datetime 
                                    < datetime[which.max(Stage_fix)]]),
          datetime_min = datetime[which.min(Stage_fix[datetime 
                                                     < datetime[which.max(Stage_fix)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2)

rbi <- filtered_washout_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_fix - lag(Stage_fix)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_fix)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

washout_stage_summ <- left_join(washout_stage_summ,
                            rbi,
                            by='event_id')


write_csv(washout_stage_summ,
          './data/final/stageResponse_2cm/washout_stage_events.csv')

```

# Bennett

```{r}

benn <- read_csv('./data/stage/bennett_all_stage.csv') %>%
  mutate(datetime = mdy_hm(datetime),
         Stage_cm = Stage_mm/10) %>%
  select(datetime, Stage_cm, site)

me <- benn %>%
  filter(site == 'me')

mm <- benn %>%
  filter(site == 'mm')

mw <- benn %>%
  filter(site == 'mw')

ue <- benn %>%
  filter(site == 'ue')

um <- benn %>%
  filter(site == 'um')

uw <- benn %>%
  filter(site == 'uw')

```

## ME

```{r}

# filter out times according to Stephanie's email
# ME: exclude all after 8/15/22 event

me_stage <- me %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9)) %>%
  filter(datetime < ymd_hms('2022-08-15 15:30:00',
                            tz = 'MST'))

################################################################################

me_stage_plot <- ggplot(me_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(me_stage_plot)
################################################################################

# Processing stage events - pt 1
filter_me_stage_events <- me_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_me_stage <- me_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_me_stage_events$start_time, 
        filter_me_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_me_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
me_stage_summ <- filtered_me_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(2:3, 13)) # noise and sensor spike

rbi <- filtered_me_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

me_stage_summ <- left_join(me_stage_summ,
                            rbi,
                            by='event_id')


write_csv(me_stage_summ,
          './data/final/stageResponse_2cm/me_stage_events.csv')

```

## MM

```{r}

# MM: missing data 10/5/22 to 6/22/23. no data after 7/12/23
mm_stage <- mm %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9)) 

################################################################################

mm_stage_plot <- ggplot(mm_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(mm_stage_plot)
################################################################################

# Processing stage events - pt 1
filter_mm_stage_events <- mm_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_mm_stage <- mm_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mm_stage_events$start_time, 
        filter_mm_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mm_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
mm_stage_summ <- filtered_mm_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(5,11,12)) # spikes from download

rbi <- filtered_mm_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))


mm_stage_summ <- left_join(mm_stage_summ,
                            rbi,
                            by='event_id')


write_csv(mm_stage_summ,
          './data/final/stageResponse_2cm/mm_stage_events.csv')

```

## MW

```{r}

#MW: data looked strange after 7/28/22 event, 
# but it did pick up 6/11/23 event. 
# I guess exclude everything between and after those two events
mw_stage <- mw %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9)) %>%
  filter(datetime < '2023-06-12 00:00:00')

################################################################################

mw_stage_plot <- ggplot(mw_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(mw_stage_plot)
################################################################################

# Processing stage events - pt 1
filter_mw_stage_events <- mw_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_mw_stage <- mw_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_mw_stage_events$start_time, 
        filter_mw_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_mw_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
mw_stage_summ <- filtered_mw_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(1,8)) # download and noise

rbi <- filtered_mw_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))

mw_stage_summ <- left_join(mw_stage_summ,
                            rbi,
                            by='event_id')
  
  
write_csv(mw_stage_summ,
          './data/final/stageResponse_2cm/mw_stage_events.csv')

```

## UE

```{r}

# UE: looks ok. ends 9/19/23
ue_stage <- ue %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9)) 

################################################################################

ue_stage_plot <- ggplot(ue_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(ue_stage_plot)

################################################################################

# Processing stage events - pt 1
filter_ue_stage_events <- ue_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_ue_stage <- ue_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_ue_stage_events$start_time, 
        filter_ue_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_ue_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
ue_stage_summ <- filtered_ue_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2)

rbi <- filtered_ue_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))


ue_stage_summ <- left_join(ue_stage_summ,
                            rbi,
                            by='event_id')


write_csv(ue_stage_summ,
          './data/final/stageResponse_2cm/ue_stage_events.csv')

```

## UM

```{r}
#UM: missing data 8/10-20/21, 10/4-15/21, 5/7/22-6/7/22, 5/22/23-7/12/23
um_stage <- um %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9))

################################################################################

um_stage_plot <- ggplot(um_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(um_stage_plot)
################################################################################

# Processing stage events - pt 1 
filter_um_stage_events <- um_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm, 4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_um_stage <- um_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_um_stage_events$start_time, 
        filter_um_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_um_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
um_stage_summ <- filtered_um_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id == 4)

rbi <- filtered_um_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))


um_stage_summ <- left_join(um_stage_summ,
                            rbi,
                            by='event_id')

write_csv(um_stage_summ,
          './data/final/stageResponse_2cm/um_stage_events.csv')

```

## UW

```{r}
# UW: looks ok, ends 9/6/23
uw_stage <- uw %>% 
  mutate(month = month(datetime)) %>% 
  filter(month %in% c(6:9)) 

################################################################################

uw_stage_plot <- ggplot(uw_stage, aes(datetime, Stage_cm)) +
  geom_line()

ggplotly(uw_stage_plot)

################################################################################

# Processing stage events - pt 1
filter_uw_stage_events <- uw_stage %>%
   mutate(pos_diff = if_else(Stage_cm - lag(Stage_cm,4) > 1.5,
                            'increase', 'none')) %>%
  filter(pos_diff == 'increase') %>%
  mutate(time_diff = as.numeric(difftime(datetime, 
                                         lag(datetime), units = 'mins'))) %>%
  mutate(event_def = if_else(time_diff < 360, 'same', 
                             'diff', missing = 'diff')) %>%
  mutate(event_id = generate_event_ids(event_def)) %>%
  group_by(event_id) %>%
  summarize(filter_time = min(datetime)) %>%
  mutate(start_time = filter_time - hours(4),
         end_time = filter_time + hours(3))

# pt 2
filtered_uw_stage <- uw_stage %>%
  rowwise() %>%
  filter(
    any(
      purrr::map2_lgl(
        filter_uw_stage_events$start_time, 
        filter_uw_stage_events$end_time, 
        ~ datetime >= .x & datetime <= .y
      )
    )
  ) %>%
  mutate(
    event_id = filter_uw_stage_events %>%
      filter(datetime >= start_time & datetime <= end_time) %>%
      pluck("event_id", 1)  # Pluck the first matching event_id
  ) %>%
  ungroup()

# pt 3
uw_stage_summ <- filtered_uw_stage %>%
  group_by(event_id) %>%
  summarize(max_stage = max(Stage_cm),
          datetime_peak = datetime[which.max(Stage_cm)],
          # Filter Stage_cm values to only those before the peak for min_stage and datetime_min
          min_stage = min(Stage_cm[datetime 
                                    < datetime[which.max(Stage_cm)]]),
          datetime_min = datetime[which.min(Stage_cm[datetime 
                                                     < datetime[which.max(Stage_cm)]])]) %>%
  mutate(stage_rise_cm = max_stage -  min_stage) %>%
  filter(stage_rise_cm > 2) %>%
  filter(!event_id %in% c(13:37, 1)) # noise

rbi <- filtered_uw_stage %>%
  group_by(event_id) %>% 
  mutate(num1 = Stage_cm - lag(Stage_cm)) %>%
  summarize(numFinal = sum(num1, na.rm=T),
            denom = sum(Stage_cm)) %>%
  mutate(rbi = numFinal / denom) %>%
  select(-c(numFinal, denom))


uw_stage_summ <- left_join(uw_stage_summ,
                            rbi,
                            by='event_id')

  
write_csv(uw_stage_summ,
          './data/final/stageResponse_2cm/uw_stage_events.csv')

```

# Join all response

```{r}

folder <- "./data/final/stageResponse_2cm"

# list csvs
csv_files <- list.files(path = folder, pattern = "stage_events\\.csv$", full.names = TRUE)

# read and join
all_stage_events <- map_dfr(csv_files, read_csv)

# all_stage_events1 <- all_stage_events %>%
#   mutate(datetime_peak = force_tz(datetime_peak, tzone = "MST"),
#           datetime_min = force_tz(datetime_min, tzone = "MST"))

write.csv(all_stage_events,
          './data/final/stageResponse_2cm/all_stage_response.csv')

# join camera data manually to all_stage_response.csv

```

# Join with MRMS events

```{r}
# add a date column to both (by end_time in mrms and datetime_peak in stage)
mrms <- read_csv('./data/final/mrms/catchment_mrms_intensities_wmean_exact_addedmetrics.csv') %>%
  mutate(start_time = mdy_hm(start_time),
         end_time = mdy_hm(end_time)) %>% 
  mutate(start_time = force_tz(start_time, tzone='MST'),
         end_time = force_tz(end_time, tzone='MST')) %>%
  mutate(ID = tolower(ID)) %>%
  rename(site = ID) %>%
  mutate(date = as.Date(end_time,
                        tz='MST'))

stage <- read_csv('./data/final/stageResponse_2cm/all_stage_response.csv') %>%
  select(-1) %>%
  mutate(datetime_peak = mdy_hm(datetime_peak),
         datetime_min = mdy_hm(datetime_min)) %>%
    mutate(datetime_peak = force_tz(datetime_peak, tzone='MST'),
           datetime_min = force_tz(datetime_min, tzone='MST')) %>%
  mutate(date = as.Date(datetime_peak,
                        tz='MST'))

# make sure site names are consistent
unique(mrms$site)
unique(stage$site)

stage_mrms <- left_join(stage,
                        mrms,
                        by=c('site',
                             'date'))
write.csv(stage_mrms,
          './data/final/stageResponse_2cm/stage_mrms_temp.csv')

# things that need to be done manually:
# - check duplicate events
# - check MRMS NA events and add in from mrms events dataset if missing

```

# Finalizing response df

```{r}

stage_mrms <- read_csv('./data/final/stageResponse_2cm/stage_mrms_temp.csv') %>%
  mutate(datetime_peak = mdy_hm(datetime_peak),
         datetime_min = mdy_hm(datetime_min),
         start_time = mdy_hm(start_time),
         end_time = mdy_hm(end_time),
         halfP_datetime = mdy_hm(halfP_datetime),
         MI60_datetime = mdy_hm(MI60_datetime)) %>%
  mutate(lag2peak_halfP = as.numeric((datetime_peak - halfP_datetime)/3600),
         lag2peak_Pstart = as.numeric((datetime_peak - start_time)/3600)) %>%
  drop_na(start_time)

# lets look outside of R 
write.csv(stage_mrms,
          './data/final/stageResponse_2cm/stage_mrms_temp2.csv')

# looked at when lag2peak_halfP was negative and fixed or deleted those events
# read back in
stage_mrms <- read_csv('./data/final/stageResponse_2cm/stage_mrms_temp2.csv') %>%
    mutate(datetime_peak = mdy_hm(datetime_peak),
         datetime_min = mdy_hm(datetime_min),
         start_time = mdy_hm(start_time),
         end_time = mdy_hm(end_time),
         halfP_datetime = mdy_hm(halfP_datetime),
         MI60_datetime = mdy_hm(MI60_datetime)) %>%
   mutate(lag2peak_halfP = as.numeric((datetime_peak - halfP_datetime)/3600),
         lag2peak_Pstart = as.numeric((datetime_peak - start_time)/60)) %>%
   drop_na(start_time)

# look at high lag to peak outside of R
write.csv(stage_mrms,
          './data/final/stageResponse_2cm/stage_mrms_temp3.csv')

# deleted two really long (~24 hr lag to peaks)
stage_mrms <- read_csv('./data/final/stageResponse_2cm/stage_mrms_temp3.csv') %>%
      mutate(datetime_peak = mdy_hm(datetime_peak),
         datetime_min = mdy_hm(datetime_min),
         start_time = mdy_hm(start_time),
         end_time = mdy_hm(end_time),
         halfP_datetime = mdy_hm(halfP_datetime),
         MI60_datetime = mdy_hm(MI60_datetime)) %>%
   mutate(lag2peak_halfP = as.numeric((datetime_peak - halfP_datetime)/3600),
         lag2peak_Pstart = as.numeric((datetime_peak - start_time)/60)) %>%
   drop_na(start_time)

# final dataset!
write.csv(stage_mrms,
          './data/final/stageResponse_2cm/stage2cm_mrms_final.csv')

```

